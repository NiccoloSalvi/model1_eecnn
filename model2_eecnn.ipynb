{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12683701,"sourceType":"datasetVersion","datasetId":8015679}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random  # for reproducibility in sampling and shuffling\nfrom pathlib import Path  # filesystem path manipulation\n\n# 2. Data handling and preprocessing\nimport numpy as np  # numerical operations\nimport pandas as pd  # dataframes and tabular data\n\n# 3. Visualization\nimport matplotlib.pyplot as plt  # plotting\nimport seaborn as sns  # statistical data visualization\n\n# 4. Deep learning (PyTorch)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n# 5. Machine learning utilities (scikit-learn)\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler  # encoding labels and feature scaling\nfrom sklearn.model_selection import train_test_split  # data splitting\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score  # evaluation metrics\n\n# 6. Learning rate schedulers\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts  # dynamic LR scheduling\n\n# Set random seeds for reproducibility\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n# Configure seaborn aesthetics\nsns.set(style='whitegrid', context='notebook')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T09:58:56.354736Z","iopub.execute_input":"2025-09-04T09:58:56.354986Z","iopub.status.idle":"2025-09-04T09:58:57.552709Z","shell.execute_reply.started":"2025-09-04T09:58:56.354968Z","shell.execute_reply":"2025-09-04T09:58:57.551958Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Dataset file paths\nTRAIN_CSV = \"/kaggle/input/har-dataset-2/train_data_2.csv\"  # Path to training data CSV\nTEST_CSV  = \"/kaggle/input/har-dataset-2/test_data_2.csv\"   # Path to testing data CSV\n\n# Windowing and batching parameters\nWINDOW_SIZE = 600           # Number of timesteps per sliding window\nBATCH_SIZE = 32             # Number of samples per training batch\nSAMPLING_FREQ = 200         # Data sampling frequency in Hz\nADD_FEATS = False           # Whether to add derived features beyond raw sensor data\n\n# Detect compute device (GPU if available, else CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:00:02.416337Z","iopub.execute_input":"2025-09-04T10:00:02.417140Z","iopub.status.idle":"2025-09-04T10:00:02.490756Z","shell.execute_reply.started":"2025-09-04T10:00:02.417103Z","shell.execute_reply":"2025-09-04T10:00:02.489986Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Data Processing Utilities and Dataset Preparation\nThis cell defines utility functions to select sensor channels, split data into training and validation sets, and loads, preprocesses, encodes, and wraps data in PyTorch datasets and dataloaders.","metadata":{}},{"cell_type":"code","source":"class DataPreprocessor:\n    def __init__(self, window_size=600, sampling_freq=200, target_samples=32):\n        self.window_size = window_size\n        self.sampling_freq = sampling_freq\n        self.target_samples = target_samples\n\n    def moving_average_filter(self, data, window=8):\n        return data.rolling(window=window, center=True).mean().fillna(data)\n\n    def segment_data(self, data, overlap=0.7):\n        segments = []\n        labels_io = []\n        labels_scene = []\n        step_size = int(self.window_size * (1 - overlap))\n\n        for i in range(0, len(data) - self.window_size, step_size):\n            window = data.iloc[i:i+self.window_size]\n\n            if len(window['I/O Detection'].unique()) == 1 and \\\n               len(window['Scene Identification'].unique()) == 1:\n                segments.append(window)\n                labels_io.append(window['I/O Detection'].iloc[0])\n                labels_scene.append(window['Scene Identification'].iloc[0])\n\n        return segments, labels_io, labels_scene\n\n    def downsample_segment(self, segment, sensor_cols):\n        downsampled = {}\n        for col in sensor_cols:\n            if col in segment.columns:\n                original_data = segment[col].values\n                indices = np.linspace(0, len(original_data) - 1, self.target_samples, dtype=int)\n                downsampled[col] = original_data[indices]\n            else:\n                downsampled[col] = np.zeros(self.target_samples)\n        return downsampled\n\n    def z_score_normalize(self, segment_data):\n        segment_array = np.array(list(segment_data.values())).T\n        mean = np.mean(segment_array, axis=0)\n        std = np.std(segment_array, axis=0)\n        std = np.where(std == 0, 1, std)\n        return (segment_array - mean) / std\n\n    def extract_statistical_features(self, segment, sensor_cols):\n        features = []\n        for col in sensor_cols:\n            if col in segment.columns:\n                values = segment[col].values\n                features.extend([\n                    np.mean(values),\n                    np.std(values),\n                    np.min(values),\n                    np.max(values)\n                ])\n        return features\n\n    def preprocess_data(self, data, sensor_cols):\n        filtered_data = data.copy()\n        for col in sensor_cols:\n            if col in data.columns:\n                filtered_data[col] = self.moving_average_filter(data[col])\n\n        segments, labels_io, labels_scene = self.segment_data(filtered_data)\n\n        processed_segments = []\n        statistical_features = []\n\n        for segment in segments:\n            if self.target_samples is not None:\n                downsampled = self.downsample_segment(segment, sensor_cols)\n                normalized = self.z_score_normalize(downsampled)\n                processed_segments.append(normalized)\n            else:\n                processed_segments.append(segment[sensor_cols].values)\n\n            stats = self.extract_statistical_features(segment, sensor_cols)\n            statistical_features.append(stats)\n\n        return np.array(processed_segments), np.array(statistical_features), labels_io, labels_scene\n\nclass HARDSdataset(Dataset):\n    def __init__(self, X, y_io, y_scene, io_label_encoder, scene_label_encoder, statistical_features=None):\n        self.X = torch.FloatTensor(X)\n        self.y_io = torch.LongTensor(y_io)\n        self.y_scene = torch.LongTensor(y_scene)\n        self.statistical_features = statistical_features\n        if statistical_features is not None:\n            self.statistical_features = torch.FloatTensor(statistical_features)\n        self.io_label_encoder = io_label_encoder\n        self.scene_label_encoder = scene_label_encoder\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        if self.statistical_features is not None:\n            return self.X[idx], self.y_io[idx], self.y_scene[idx], self.statistical_features[idx]\n        return self.X[idx], self.y_io[idx], self.y_scene[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:00:27.601633Z","iopub.execute_input":"2025-09-04T10:00:27.602296Z","iopub.status.idle":"2025-09-04T10:00:27.620176Z","shell.execute_reply.started":"2025-09-04T10:00:27.602266Z","shell.execute_reply":"2025-09-04T10:00:27.619292Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Function to map high-level sensor names to their corresponding DataFrame columns\ndef get_sensors(sensor_list):\n    # Dictionary of available sensor groups and their DataFrame columns\n    available_sensors = {\n        \"Accelerometer\": [\"A_x [g]_y\", \"A_y [g]_y\", \"A_z [g]_y\"],\n        \"Magnetometer\": [\"M_x [gauss]\", \"M_y [gauss]\", \"M_z [gauss]\"],\n        \"Gyroscope\": [\"G_x [mdps]\", \"G_y [mdps]\", \"G_z [mdps]\"],\n        \"Temperature\": [\"TEMP\"],\n        \"Pressure\": [\"PRESS\"],\n    }\n\n    # If user requests all sensors, return every column\n    if sensor_list == 'all':\n        return [col for cols in available_sensors.values() for col in cols]\n\n    selected_sensors = []\n    # Iterate through requested sensor names\n    for sensor in sensor_list:\n        # Raise error if sensor name is invalid\n        if sensor not in available_sensors:\n            raise ValueError(\n                f\"Sensor '{sensor}' is not available. Choose from {list(available_sensors.keys())}\"\n            )\n        # Append all columns for the valid sensor\n        selected_sensors.extend(available_sensors[sensor])\n\n    return selected_sensors\n\n# Function to split data arrays into train and validation subsets\ndef split_train_validation(X, y_io, y_scene, stats, val_split=0.2, stratify_on=None):\n    # Use stratified split if a column is provided for stratification\n    if stratify_on is not None:\n        X_train, X_val, y_io_train, y_io_val, y_scene_train, y_scene_val, stats_train, stats_val = train_test_split(\n            X, y_io, y_scene, stats,\n            test_size=val_split,\n            random_state=42,\n            stratify=stratify_on\n        )\n    else:\n        # Simple contiguous split if no stratification\n        split_idx = int((1 - val_split) * len(X))\n        X_train, X_val = X[:split_idx], X[split_idx:]\n        y_io_train, y_io_val = y_io[:split_idx], y_io[split_idx:]\n        y_scene_train, y_scene_val = y_scene[:split_idx], y_scene[split_idx:]\n        stats_train, stats_val = stats[:split_idx], stats[split_idx:]\n\n    return (\n        X_train, X_val,\n        y_io_train, y_io_val,\n        y_scene_train, y_scene_val,\n        stats_train, stats_val\n    )\n\ndef print_distribution(name, labels, encoder):\n    # labels: 1D array of encoded ints\n    unique_lbls, counts = np.unique(labels, return_counts=True)\n    print(f\"\\n=== {name} Set ===\")\n    for enc, cnt in zip(unique_lbls, counts):\n        human = encoder.inverse_transform([enc])[0]\n        print(f\"  {human:>10s}: {cnt}\")\n\n# Prepare sensor list and data preprocessor\nsensors = get_sensors('all')  # Retrieve all sensor columns\npreprocessor = DataPreprocessor(window_size=WINDOW_SIZE, target_samples=None)\n\n# Load raw CSV data\ntrain_data = pd.read_csv(TRAIN_CSV)\ntest_data = pd.read_csv(TEST_CSV)\n\n# Preprocess data into feature windows, stats, and labels\nX_train, stats_train, y_io_train, y_scene_train = preprocessor.preprocess_data(train_data, sensors)\nX_test, stats_test, y_io_test, y_scene_test = preprocessor.preprocess_data(test_data, sensors)\n\n# Print data shapes and unique classes for sanity\nprint(f\"Training data shape: {X_train.shape}\")\nprint(f\"Test data shape: {X_test.shape}\")\nprint(f\"Unique I/O classes: {np.unique(y_io_train)}\")\nprint(f\"Unique Scene classes: {np.unique(y_scene_train)}\")\n\n# Encode string labels to integers for I/O and Scene tasks\nio_encoder = LabelEncoder()\nscene_encoder = LabelEncoder()\n\ny_io_train_encoded = io_encoder.fit_transform(y_io_train)\ny_scene_train_encoded = scene_encoder.fit_transform(y_scene_train)\ny_io_test_encoded = io_encoder.transform(y_io_test)\ny_scene_test_encoded = scene_encoder.transform(y_scene_test)\n\n# Number of classes for each task\nnum_io_classes = len(io_encoder.classes_)\nnum_scene_classes = len(scene_encoder.classes_)\n\nprint(f\"Number of I/O classes: {num_io_classes}\")\nprint(f\"Number of Scene classes: {num_scene_classes}\")\n\n# Split data into training and validation sets\nX_train_split, X_val, y_io_train_split, y_io_val, y_scene_train_split, y_scene_val, stats_train_split, stats_val = split_train_validation(\n    X_train, y_io_train_encoded, y_scene_train_encoded,\n    stats_train,\n    val_split=0.2,\n    stratify_on=y_scene_train_encoded  # Stratify by scene class distribution\n)\n\n# Decode validation labels for potential inspection or debugging\ny_io_val_decoded = io_encoder.inverse_transform(y_io_val)\ny_scene_val_decoded = scene_encoder.inverse_transform(y_scene_val)\n\n# %% [code]\n# Create PyTorch datasets for train, validation, and test splits\ntrain_dataset = HARDSdataset(X_train_split, y_io_train_split, y_scene_train_split, io_encoder, scene_encoder)\nval_dataset = HARDSdataset(X_val, y_io_val, y_scene_val, io_encoder, scene_encoder)\ntest_dataset = HARDSdataset(X_test, y_io_test_encoded, y_scene_test_encoded, io_encoder, scene_encoder)\n\n# Build DataLoaders for batching during training and evaluation\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4,\n    pin_memory=torch.cuda.is_available()\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=torch.cuda.is_available()\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=torch.cuda.is_available()\n)\n\n# Print dataset sizes for verification\nprint(f\"Train samples: {len(train_loader.dataset)}\")\nprint(f\"Val samples:   {len(val_loader.dataset)}\")\nprint(f\"Test samples:  {len(test_loader.dataset)}\")\n\n# Print dataset labels distributions\nprint_distribution(\"Train I/O\",   train_dataset.y_io,    train_dataset.io_label_encoder)\nprint_distribution(\"Train Scene\", train_dataset.y_scene, train_dataset.scene_label_encoder)\n\nprint_distribution(\"Val I/O\",     val_dataset.y_io,      val_dataset.io_label_encoder)\nprint_distribution(\"Val Scene\",   val_dataset.y_scene,   val_dataset.scene_label_encoder)\n\nprint_distribution(\"Test I/O\",    test_dataset.y_io,     test_dataset.io_label_encoder)\nprint_distribution(\"Test Scene\",  test_dataset.y_scene,  test_dataset.scene_label_encoder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:00:30.443468Z","iopub.execute_input":"2025-09-04T10:00:30.444111Z","iopub.status.idle":"2025-09-04T10:01:38.714965Z","shell.execute_reply.started":"2025-09-04T10:00:30.444079Z","shell.execute_reply":"2025-09-04T10:01:38.714188Z"}},"outputs":[{"name":"stdout","text":"Training data shape: (21476, 600, 11)\nTest data shape: (5342, 600, 11)\nUnique I/O classes: ['Indoor' 'Outdoor']\nUnique Scene classes: ['Bar' 'Hallway' 'Office' 'Street']\nNumber of I/O classes: 2\nNumber of Scene classes: 4\nTrain samples: 17180\nVal samples:   4296\nTest samples:  5342\n\n=== Train I/O Set ===\n      Indoor: 12321\n     Outdoor: 4859\n\n=== Train Scene Set ===\n         Bar: 4000\n     Hallway: 2611\n      Office: 5710\n      Street: 4859\n\n=== Val I/O Set ===\n      Indoor: 3081\n     Outdoor: 1215\n\n=== Val Scene Set ===\n         Bar: 1000\n     Hallway: 653\n      Office: 1428\n      Street: 1215\n\n=== Test I/O Set ===\n      Indoor: 3809\n     Outdoor: 1533\n\n=== Test Scene Set ===\n         Bar: 828\n     Hallway: 1097\n      Office: 1884\n      Street: 1533\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Access the label encoders from your dataset object\nio_encoder = train_loader.dataset.io_label_encoder\nscene_encoder = train_loader.dataset.scene_label_encoder\n\n# The .classes_ attribute holds the class names in order of their integer encoding (0, 1, 2, ...)\nprint(\"I/O Encoder Classes:\", io_encoder.classes_)\nprint(\"Scene Encoder Classes:\", scene_encoder.classes_)\n\n# For a more robust way to use this in your code, create a mapping dictionary\nio_map = {name: i for i, name in enumerate(io_encoder.classes_)}\nscene_map = {name: i for i, name in enumerate(scene_encoder.classes_)}\n\nprint(\"\\n--- Mappings ---\")\nprint(\"I/O Mapping:\", io_map)\nprint(\"Scene Mapping:\", scene_map)\n\n# Now you can directly use the names to get the encoding\nprint(f\"\\nEncoding for 'Indoor': {io_map['Indoor']}\")\nprint(f\"Encoding for 'Outdoor': {io_map['Outdoor']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:18:09.063420Z","iopub.execute_input":"2025-09-03T15:18:09.063690Z","iopub.status.idle":"2025-09-03T15:18:09.069474Z","shell.execute_reply.started":"2025-09-03T15:18:09.063670Z","shell.execute_reply":"2025-09-03T15:18:09.068747Z"}},"outputs":[{"name":"stdout","text":"I/O Encoder Classes: ['Indoor' 'Outdoor']\nScene Encoder Classes: ['Bar' 'Hallway' 'Office' 'Street']\n\n--- Mappings ---\nI/O Mapping: {'Indoor': 0, 'Outdoor': 1}\nScene Mapping: {'Bar': 0, 'Hallway': 1, 'Office': 2, 'Street': 3}\n\nEncoding for 'Indoor': 0\nEncoding for 'Outdoor': 1\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Depthwise Separable Convolution and Early-Exit CNN Module","metadata":{}},{"cell_type":"code","source":"# ------------------------------\n# Depthwise separable 1D conv\n# ------------------------------\ndef depthwise_separable_conv1d(in_ch, out_ch, kernel_size, stride=1, padding=0, drop_p=0.15, dilation=1):\n    return nn.Sequential(\n        nn.Conv1d(in_ch, in_ch, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_ch, bias=False),\n        nn.BatchNorm1d(in_ch),\n        nn.ReLU(inplace=True),\n        nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False),\n        nn.BatchNorm1d(out_ch),\n        nn.ReLU(inplace=True),\n        nn.Dropout1d(drop_p)\n    )\n\nclass DepthwiseEarlyExitCNN1D(nn.Module):\n    def __init__(self, if_train, train_shape, n_io, n_scene):\n        super().__init__()\n        self.if_train = if_train\n        seq_len, n_sensors = train_shape\n\n        # Backbone\n        self.backbone0 = nn.Sequential(\n            depthwise_separable_conv1d(n_sensors, 16, kernel_size=7, stride=2, padding=3, drop_p=0.1),\n            depthwise_separable_conv1d(16, 16, kernel_size=5, stride=2, padding=2, drop_p=0.1)\n        )\n\n        # Branches\n        self.io_branch = depthwise_separable_conv1d(16, 32, kernel_size=6, stride=3, padding=2, drop_p=0.15)\n        self.scene_branch = nn.Sequential(\n            depthwise_separable_conv1d(16, 32, kernel_size=5, stride=2, padding=2, drop_p=0.1),\n            depthwise_separable_conv1d(32, 32, kernel_size=3, stride=2, padding=1, drop_p=0.1)\n        )\n\n        self.gap = nn.AdaptiveAvgPool1d(1)\n\n        # Exit-0 (early I/O): pool inside head (as before)\n        self.io_head0 = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1), nn.Flatten(), nn.Linear(16, n_io)\n        )\n\n        # Exit-1 heads (conv-only fusion)\n        # I/O fusion: [x0_gap=16] + [x1_io_gap=32] = 48\n        self.io_head1 = nn.Sequential(\n            nn.Linear(48, 48), nn.ReLU(inplace=True), nn.Dropout(0.15), nn.Linear(48, n_io)\n        )\n        # Scene fusion: [x1_sc_gap=32] = 32\n        self.scene_head1 = nn.Sequential(\n            nn.Linear(32, 32), nn.ReLU(inplace=True), nn.Dropout(0.15), nn.Linear(32, n_scene)\n        )\n\n    # max softmax confidence\n    def get_confidence(self, logits):\n        return F.softmax(logits, dim=-1).amax(dim=-1)\n\n    @staticmethod\n    def _is_depth_allowed(battery_level):\n        try:\n            return (allowed_depth(battery_level) != 1)\n        except Exception:\n            return True\n\n    def forward(self, x, battery_level=1.0, return_all=False):\n        # [B, T, C] -> [B, C, T]\n        x = x.permute(0, 2, 1)\n\n        # -------- Stage 1 (E0: I/O) --------\n        x0 = self.backbone0(x) # [B, 16, ·]\n        e0io = self.io_head0(x0) # [B, n_io]\n        conf0 = self.get_confidence(e0io)\n\n        tau = tau_sigmoid(battery_level, k=8.0)\n\n        # Early return (true inference path only)\n        if not self.if_train and not return_all:\n            depth_allowed = self._is_depth_allowed(battery_level)\n            # Keep the fast path when ALL samples in the batch are confident (or depth not allowed).\n            if (not depth_allowed) or bool((conf0 >= tau).all().item()):\n                return [e0io], 1\n\n        # -------- Stage 2 (Deep conv features) --------\n        x1_io = self.io_branch(x0) # [B, 32, ·]\n        x1_scene = self.scene_branch(x0) # [B, 32, ·]\n        \n        # GAP features\n        x0_gap = self.gap(x0).flatten(1) # [B, 16]\n        x1io_gap = self.gap(x1_io).flatten(1) # [B, 32]\n        x1sc_gap = self.gap(x1_scene).flatten(1) # [B, 32]\n\n        # Heads (conv-only fusions)\n        io_feat = torch.cat([x0_gap, x1io_gap], dim=1) # [B, 48]\n        e1io = self.io_head1(io_feat) # [B, n_io]\n\n        sc_feat = x1sc_gap # [B, 32]\n        e1sc = self.scene_head1(sc_feat) # [B, n_scene]\n\n        # Exit probs (optional logging only)\n        should_exit0 = (conf0 >= tau).float()\n        p_exits = torch.stack([should_exit0, 1.0 - should_exit0], dim=1)\n\n        # Return set\n        if self.if_train or return_all:\n            return [e0io, e1sc, e1io], p_exits\n\n        # Inference deep path chosen\n        io_final = e1io\n        return [io_final, e1sc], 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T09:59:04.308604Z","iopub.execute_input":"2025-09-04T09:59:04.309150Z","iopub.status.idle":"2025-09-04T09:59:04.322057Z","shell.execute_reply.started":"2025-09-04T09:59:04.309125Z","shell.execute_reply":"2025-09-04T09:59:04.321330Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"def allowed_depth(battery_level):\n    b = float(battery_level.min().item()) if torch.is_tensor(battery_level) else float(battery_level)\n    return 1 if b < 0.20 else 2\n\ndef map_battery(b, k=10.0, center=0.5):\n    \"\"\"\n    Map battery_level to sensitivity curve via sigmoid centered at 0.5.\n    More sensitive around mid battery range.\n    \"\"\"\n    return torch.sigmoid(k*(b-center))\n    \ndef tau_sigmoid(b, k=10.0, center=0.5, min_tau=0.80, max_tau=0.98):\n    \"\"\"\n    Mappa il livello della batteria a una soglia di confidenza τ usando una sigmoide.\n    - k: Controlla la ripidità della transizione. Valori più bassi = transizione più dolce.\n    - center: Il livello di batteria attorno al quale avviene il cambiamento più rapido.\n    - min_tau / max_tau: L'intervallo della soglia.\n    \"\"\"\n    if not torch.is_tensor(b):\n        b = torch.tensor(b)\n        \n    # La sigmoide mappa b (0,1) a un valore (0,1)\n    sensitivity = torch.sigmoid(k * (b - center))\n    \n    # Mappa linearmente l'output della sigmoide all'intervallo [min_tau, max_tau]\n    tau = min_tau + (max_tau - min_tau) * sensitivity\n    \n    return tau.clamp_(0.50, 0.999)\n\ndef battery_sampler_uniform(batch_size):\n    \"\"\"\n    Returns a tensor of shape (batch_size,)\n    with battery levels sampled uniformly in [0, 1].\n    \"\"\"\n    return torch.rand(batch_size)\n\ndef battery_sampler_beta(batch_size, alpha=2.0, beta=5.0):\n    \"\"\"\n    Returns a tensor of shape (batch_size,)\n    with battery levels sampled from a Beta distribution.\n    \n    Parameters:\n    - alpha, beta: shape parameters of the Beta distribution.\n      A Beta(2,5) mimics a device which spends more time at lower charge.\n    \"\"\"\n    return torch.distributions.Beta(alpha, beta).sample((batch_size,))\n\ndef battery_sampler_schedule(batch_size, start=1.0, end=0.0, epoch=0, total_epochs=100):\n    \"\"\"\n    Returns a tensor where battery levels linearly decay over training epochs.\n    Useful for curriculum learning.\n    \n    Parameters:\n    - start: initial battery level at epoch=0\n    - end: final battery level at epoch=total_epochs\n    - epoch: current epoch index\n    - total_epochs: total number of epochs\n    \"\"\"\n    level = start + (end - start) * (epoch / (total_epochs - 1))\n    return torch.full((batch_size,), level)\n\ndef compute_inverse_freq_weights(class_counts):\n    \"\"\"\n    Calcola i pesi basati sull'inverso della frequenza.\n    \"\"\"\n    counts = np.array(class_counts, dtype=np.float32)\n    total = counts.sum()\n    num_classes = len(counts)\n    \n    weights = total / (num_classes * counts)\n    \n    return torch.tensor(weights, dtype=torch.float32)\n    \ndef focal_loss(logits, targets, class_weights=None, alpha=1.0, gamma=2.0):\n    # Usiamo la cross-entropy standard ma senza ridurre (aggregare) la loss\n    ce_loss = F.cross_entropy(logits, targets, reduction='none', weight=class_weights)\n    \n    # pt è la probabilità della classe corretta\n    pt = torch.exp(-ce_loss)\n    \n    # Calcoliamo la focal loss\n    f_loss = alpha * (1 - pt)**gamma * ce_loss\n    \n    return f_loss.mean()\n\nclass AdvancedSceneLoss(nn.Module):\n    def __init__(self, class_weights, device='cpu', use_focal=False, gamma=2.0, alpha=1.0):\n        super().__init__()\n        self.class_weights = class_weights.to(device)\n        self.use_focal = use_focal\n        self.gamma = gamma\n        self.alpha = alpha\n        \n    def forward(self, logits, targets):\n        \"\"\"\n        Args:\n            logits: [batch_size, n_classes] predizioni della scena\n            targets: [batch_size] indici di classe\n        \"\"\"\n        if self.use_focal:\n            # Usa la nostra nuova funzione di focal loss\n            return focal_loss(\n                logits, \n                targets, \n                class_weights=self.class_weights,\n                gamma=self.gamma,\n                alpha=self.alpha\n            )\n        else:\n            # Comportamento precedente: Cross-Entropy pesata\n            return F.cross_entropy(\n                logits, \n                targets, \n                weight=self.class_weights\n            )\n\ntrain_scene_counts = [4000, 2611, 5710, 4859]\ncomputed_weights = compute_inverse_freq_weights(train_scene_counts)\nmanual_scene_weights = torch.tensor([1.0, 2.0, 2.0, 1.0])  # Higher weight for Hallway, Office","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:02:31.952044Z","iopub.execute_input":"2025-09-04T10:02:31.952316Z","iopub.status.idle":"2025-09-04T10:02:31.966266Z","shell.execute_reply.started":"2025-09-04T10:02:31.952296Z","shell.execute_reply":"2025-09-04T10:02:31.965715Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def _top1_correct(logits: torch.Tensor, labels: torch.Tensor):\n    \"\"\"Returns (#correct, #samples) for top-1 accuracy.\"\"\"\n    return (logits.argmax(dim=1) == labels).sum().item(), labels.size(0)\n\ndef run_epoch(model, loader, criterion, optimizer, scheduler, train, battery_sampler=None):\n    # We want p_exits from the model even in eval, so keep if_train=True\n    model.if_train = True\n    model.train() if train else model.eval()\n\n    # MODIFIED: Expanded stats dict to track all heads individually\n    stats = {\n        \"loss_total\": 0.0,\n        \"n\":          0,\n        \"correct_io0\": 0,  # Correct predictions for I/O at Exit 0\n        \"correct_sc1\": 0,  # Correct predictions for Scene at Exit 1\n        \"correct_io1\": 0,  # Correct predictions for I/O at Exit 1\n    }\n\n    with torch.set_grad_enabled(train):\n        for feats, io_lbls, sc_lbls in loader:\n            feats   = feats.float().to(device)       # [B,T,C]\n            io_lbls = io_lbls.view(-1).to(device)    # [B]\n            sc_lbls = sc_lbls.view(-1).to(device)    # [B]\n            B = feats.size(0)\n\n            batt = (battery_sampler(B).to(device) if battery_sampler else torch.ones(B, device=device))\n\n            # Model returns: (e0io, e1sc, e1io), p_exits with p_exits shape [B,2]\n            (e0io, e1sc, e1io), p_exits = model(feats, battery_level=batt)\n            # --- losses ---\n            loss_e0io = criterion(e0io, io_lbls)         # I/O @ exit-1\n            # loss_e1sc = weighted_scene_loss(e1sc, sc_lbls) # Scene @ exit-2\n            advanced_scene_loss = AdvancedSceneLoss(\n                class_weights=manual_scene_weights, \n                device=device,\n                use_focal=True,\n                gamma=2.0 \n            )\n            loss_e1sc = advanced_scene_loss(e1sc, sc_lbls)\n\n            # I/O deep (only care about late subset): weight by p(exit=2)\n            w_late = p_exits[:, 1].detach()              # [B]\n            loss_e1io_per = F.cross_entropy(e1io, io_lbls, reduction='none')  # [B]\n            loss_e1io = (w_late * loss_e1io_per).mean()\n\n            # Classification loss mix\n            w0, w1, w0d = 3.0, 20.0, 8.0\n            cls_loss = (w0*loss_e0io + w1*loss_e1sc + w0d*loss_e1io) / (w0+w1+w0d)\n            \n            loss = cls_loss\n\n            if train:\n                optimizer.zero_grad()\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n                \n            # --- stats ---\n            stats[\"loss_total\"] += loss.item() * B\n            stats[\"n\"] += B\n\n            # MODIFIED: Calculate accuracy for ALL heads on ALL samples.\n            # This allows you to see the raw performance of each head before the exit policy is applied.\n            c, _ = _top1_correct(e0io, io_lbls)\n            stats[\"correct_io0\"] += c\n            \n            c, _ = _top1_correct(e1sc, sc_lbls)\n            stats[\"correct_sc1\"] += c\n\n            # This is the crucial new metric you need to watch.\n            c, _ = _top1_correct(e1io, io_lbls)\n            stats[\"correct_io1\"] += c\n\n    n = stats[\"n\"]\n    losses = {\n        \"total\":   stats[\"loss_total\"] / n\n    }\n    \n    # MODIFIED: Renamed and expanded the accuracies dictionary for clarity.\n    accs = {\n        \"io@0_early\": stats[\"correct_io0\"] / n,\n        \"sc@1_deep\":  stats[\"correct_sc1\"] / n,\n        \"io@1_deep\":  stats[\"correct_io1\"] / n, # The accuracy of the second I/O head\n    }\n    return losses, accs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:18:14.796338Z","iopub.execute_input":"2025-09-03T15:18:14.796985Z","iopub.status.idle":"2025-09-03T15:18:14.806452Z","shell.execute_reply.started":"2025-09-03T15:18:14.796963Z","shell.execute_reply":"2025-09-03T15:18:14.805830Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train_model(train_loader, val_loader, hparams, save_dir, run_name):\n    run_save_dir = Path(save_dir) / run_name\n    run_save_dir.mkdir(parents=True, exist_ok=True)\n\n    # ── model ----------------------------------------------------------------\n    sample_shape = train_loader.dataset[0][0].shape\n    model = DepthwiseEarlyExitCNN1D(\n        True,\n        sample_shape,\n        len(train_loader.dataset.io_label_encoder.classes_),\n        len(train_loader.dataset.scene_label_encoder.classes_)\n    ).to(device)\n\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=hparams[\"lr\"], weight_decay=hparams[\"weight_decay\"])\n\n    # ── scheduler ------------------------------------------------------------\n    if hparams[\"scheduler\"] == \"cosine\": \n        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=hparams[\"t0\"], T_mult=hparams[\"tmult\"], eta_min=hparams[\"eta_min\"])\n    elif hparams[\"scheduler\"] == \"step\":\n        scheduler = StepLR(optimizer, step_size=hparams[\"step_size\"], gamma=0.5)\n    elif hparams[\"scheduler\"] == \"plateau\":\n        scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=5, min_lr=1e-7)\n    elif hparams[\"scheduler\"] == \"onecycle\":\n        total_steps = hparams[\"epochs\"] * len(train_loader)\n        scheduler = OneCycleLR(optimizer, max_lr=1e-2, total_steps=total_steps, pct_start=hparams[\"pc\"], div_factor=hparams[\"divfactor\"], final_div_factor=1e4)\n    else: \n        raise ValueError(f\"Unsupported scheduler: {hparams['scheduler']}\")\n\n    # ── early-stopping config -----------------------------------------------\n    monitor = \"total\"\n    higher_is_better = False               # flip if you monitor a loss\n    min_delta = 1e-4\n    patience = 25\n\n    best_value = -float(\"inf\") if higher_is_better else float(\"inf\")\n    epochs_no_improve = 0\n    history = []\n\n    # ── epoch loop -----------------------------------------------------------\n    for epoch in range(1, hparams[\"epochs\"] + 1):\n        # ---- train ----------------------------------------------------------\n        tr_losses, tr_accs = run_epoch(\n            model, train_loader, criterion, optimizer, scheduler, True,\n            battery_sampler=lambda bs: battery_sampler_schedule(bs, epoch=epoch, total_epochs=hparams[\"epochs\"])\n        )\n\n        # ---- validation -----------------------------------------------------\n        vl_losses, vl_accs = run_epoch(\n            model, val_loader, criterion, None, None, False,\n            battery_sampler=lambda bs: torch.ones(bs, device=device)\n        )\n\n        # ---- scheduler step -------------------------------------------------\n        if hparams[\"scheduler\"] == \"step\":\n            scheduler.step()\n        elif hparams[\"scheduler\"] == \"plateau\":\n            scheduler.step(vl_losses[monitor])\n        elif hparams[\"scheduler\"] == \"onecycle\":\n            scheduler.step()\n        elif hparams[\"scheduler\"] == \"cosine\":\n            scheduler.step()\n\n        # ---- pretty log -----------------------------------------------------\n        print(\n            f\"Ep {epoch:03d} | \"\n            f\"tr L:{tr_losses['total']:.3f} \"\n            f\"IO_0[{tr_accs['io@0_early']:.2%}] \"\n            f\"IO_1[{tr_accs['io@1_deep']:.2%}] \"\n            f\"SC_1[{tr_accs['sc@1_deep']:.2%}] | \"\n            f\"vl L:{vl_losses['total']:.3f} \"\n            f\"IO_0[{vl_accs['io@0_early']:.2%}] \"\n            f\"IO_1[{vl_accs['io@1_deep']:.2%}] \"\n            f\"SC_1[{vl_accs['sc@1_deep']:.2%}] \"\n        )\n\n        # ---- early-stopping -------------------------------------------------\n        curr_value = vl_losses[monitor]\n        improved = (curr_value > best_value + min_delta) if higher_is_better else (curr_value < best_value - min_delta)\n\n        if improved:\n            best_value = curr_value\n            epochs_no_improve = 0\n            torch.save({\n                \"model\": model.state_dict(),\n                \"train_shape\": train_loader.dataset[0][0].shape,  # (T, C)\n                \"io_classes\":   list(train_dataset.io_label_encoder.classes_),\n                \"scene_classes\":list(train_dataset.scene_label_encoder.classes_),\n            }, str(run_save_dir) + \"/best_model.pth\")\n            print(f\" -> Saved best model ({monitor}: {best_value:.4f})\")\n        else:\n            epochs_no_improve += 1\n            print(f\" -> No improvement on {monitor} ({epochs_no_improve}/{patience})\")\n\n        if epochs_no_improve >= patience:\n            print(f\" -> Early stopping at epoch {epoch}\")\n            break\n\n        # ---- bookkeeping ----------------------------------------------------\n        history.append({\n            \"epoch\" : epoch,\n            **{f\"tr_{k}\": v for k, v in tr_losses.items()},\n            **{f\"vl_{k}\": v for k, v in vl_losses.items()}\n        })\n\n    print(f\"END RUN: {run_name} | best {monitor}: {best_value:.4f}\")\n    \n    return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:18:17.317222Z","iopub.execute_input":"2025-09-03T15:18:17.317713Z","iopub.status.idle":"2025-09-03T15:18:17.330178Z","shell.execute_reply.started":"2025-09-03T15:18:17.317690Z","shell.execute_reply":"2025-09-03T15:18:17.329595Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# List of hyperparameter combinations to explore\nhyperparameter_space = [\n    # best ones\n    # {'lr': 5e-3, 'weight_decay': 4e-5, 'scheduler': 'cosine', 'epochs': 100, 't0': 25, 'tmult': 1, 'eta_min': 1e-5, 'x': 115}, # WOWW\n    {'lr': 4e-4, 'weight_decay': 1e-4, 'scheduler': 'cosine', 'epochs': 100, 't0': 15, 'tmult': 2, 'eta_min': 3e-5, 'x': 1}, # WOWW #118 was good\n]\n\n# Directory to save checkpoint runs\nSAVE_DIR = \"/kaggle/working/validation_runs\"\n\n# Dictionary to collect training histories\nall_histories = {}\nfor hparams in hyperparameter_space:\n    # Construct a short run name for saving and lookup\n    run_name = f\"LR_{hparams['lr']}_WD_{hparams['weight_decay']}_SCH_{hparams['scheduler']}_X{hparams['x']}\"\n    print(f'\\nTraining: {run_name}')\n    # Train the model with the given hyperparameters\n    history = train_model(\n        train_loader=train_loader,\n        val_loader=val_loader,\n        hparams=hparams,\n        save_dir=SAVE_DIR,\n        run_name=run_name\n    )\n    # Store history for analysis and comparison\n    all_histories[run_name] = history\n\nprint(\"Hyperparameter tuning completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:18:22.991627Z","iopub.execute_input":"2025-09-03T15:18:22.992157Z","iopub.status.idle":"2025-09-03T15:33:18.390409Z","shell.execute_reply.started":"2025-09-03T15:18:22.992129Z","shell.execute_reply":"2025-09-03T15:33:18.389523Z"}},"outputs":[{"name":"stdout","text":"\nTraining: LR_0.0004_WD_0.0001_SCH_cosine_X1\nEp 001 | tr L:0.834 IO_0[71.68%] IO_1[75.22%] SC_1[48.43%] | vl L:0.592 IO_0[71.67%] IO_1[83.01%] SC_1[58.17%] \n -> Saved best model (total: 0.5916)\nEp 002 | tr L:0.628 IO_0[74.06%] IO_1[82.12%] SC_1[57.11%] | vl L:0.515 IO_0[76.49%] IO_1[84.52%] SC_1[64.01%] \n -> Saved best model (total: 0.5151)\nEp 003 | tr L:0.570 IO_0[76.85%] IO_1[83.42%] SC_1[61.16%] | vl L:0.449 IO_0[79.05%] IO_1[85.45%] SC_1[68.44%] \n -> Saved best model (total: 0.4489)\nEp 004 | tr L:0.534 IO_0[78.40%] IO_1[84.00%] SC_1[64.18%] | vl L:0.420 IO_0[79.31%] IO_1[86.10%] SC_1[69.37%] \n -> Saved best model (total: 0.4204)\nEp 005 | tr L:0.502 IO_0[79.13%] IO_1[84.39%] SC_1[66.25%] | vl L:0.397 IO_0[80.59%] IO_1[87.06%] SC_1[73.37%] \n -> Saved best model (total: 0.3970)\nEp 006 | tr L:0.472 IO_0[78.98%] IO_1[85.15%] SC_1[68.42%] | vl L:0.388 IO_0[80.14%] IO_1[88.13%] SC_1[74.95%] \n -> Saved best model (total: 0.3884)\nEp 007 | tr L:0.459 IO_0[79.92%] IO_1[85.17%] SC_1[70.06%] | vl L:0.344 IO_0[82.19%] IO_1[88.76%] SC_1[77.96%] \n -> Saved best model (total: 0.3438)\nEp 008 | tr L:0.447 IO_0[80.33%] IO_1[85.85%] SC_1[70.67%] | vl L:0.328 IO_0[83.99%] IO_1[87.66%] SC_1[79.56%] \n -> Saved best model (total: 0.3282)\nEp 009 | tr L:0.438 IO_0[80.81%] IO_1[86.07%] SC_1[71.15%] | vl L:0.353 IO_0[82.03%] IO_1[89.15%] SC_1[77.54%] \n -> No improvement on total (1/25)\nEp 010 | tr L:0.445 IO_0[80.66%] IO_1[85.97%] SC_1[70.87%] | vl L:0.323 IO_0[84.17%] IO_1[89.22%] SC_1[79.10%] \n -> Saved best model (total: 0.3226)\nEp 011 | tr L:0.426 IO_0[81.48%] IO_1[86.25%] SC_1[71.83%] | vl L:0.327 IO_0[83.61%] IO_1[89.62%] SC_1[77.86%] \n -> No improvement on total (1/25)\nEp 012 | tr L:0.427 IO_0[81.72%] IO_1[86.24%] SC_1[71.54%] | vl L:0.314 IO_0[84.50%] IO_1[89.92%] SC_1[80.03%] \n -> Saved best model (total: 0.3139)\nEp 013 | tr L:0.423 IO_0[81.76%] IO_1[86.23%] SC_1[71.86%] | vl L:0.306 IO_0[84.54%] IO_1[89.69%] SC_1[80.91%] \n -> Saved best model (total: 0.3065)\nEp 014 | tr L:0.420 IO_0[81.33%] IO_1[86.62%] SC_1[72.49%] | vl L:0.297 IO_0[84.82%] IO_1[89.20%] SC_1[80.89%] \n -> Saved best model (total: 0.2971)\nEp 015 | tr L:0.423 IO_0[81.48%] IO_1[86.31%] SC_1[71.90%] | vl L:0.304 IO_0[84.78%] IO_1[89.59%] SC_1[80.38%] \n -> No improvement on total (1/25)\nEp 016 | tr L:0.416 IO_0[81.86%] IO_1[86.55%] SC_1[72.27%] | vl L:0.305 IO_0[84.50%] IO_1[89.69%] SC_1[78.68%] \n -> No improvement on total (2/25)\nEp 017 | tr L:0.413 IO_0[82.07%] IO_1[86.80%] SC_1[72.46%] | vl L:0.286 IO_0[85.15%] IO_1[90.43%] SC_1[80.98%] \n -> Saved best model (total: 0.2863)\nEp 018 | tr L:0.405 IO_0[82.49%] IO_1[86.75%] SC_1[73.21%] | vl L:0.318 IO_0[83.33%] IO_1[90.76%] SC_1[78.42%] \n -> No improvement on total (1/25)\nEp 019 | tr L:0.385 IO_0[82.51%] IO_1[87.73%] SC_1[74.80%] | vl L:0.260 IO_0[85.89%] IO_1[90.92%] SC_1[82.52%] \n -> Saved best model (total: 0.2602)\nEp 020 | tr L:0.389 IO_0[82.95%] IO_1[87.67%] SC_1[73.91%] | vl L:0.277 IO_0[85.22%] IO_1[91.27%] SC_1[81.59%] \n -> No improvement on total (1/25)\nEp 021 | tr L:0.372 IO_0[83.23%] IO_1[88.13%] SC_1[74.84%] | vl L:0.265 IO_0[84.45%] IO_1[91.50%] SC_1[82.91%] \n -> No improvement on total (2/25)\nEp 022 | tr L:0.367 IO_0[83.07%] IO_1[88.20%] SC_1[75.81%] | vl L:0.271 IO_0[85.87%] IO_1[91.46%] SC_1[81.84%] \n -> No improvement on total (3/25)\nEp 023 | tr L:0.368 IO_0[83.45%] IO_1[88.30%] SC_1[75.28%] | vl L:0.250 IO_0[84.89%] IO_1[91.78%] SC_1[82.73%] \n -> Saved best model (total: 0.2495)\nEp 024 | tr L:0.357 IO_0[83.70%] IO_1[88.31%] SC_1[75.60%] | vl L:0.249 IO_0[85.24%] IO_1[91.76%] SC_1[82.17%] \n -> Saved best model (total: 0.2486)\nEp 025 | tr L:0.357 IO_0[83.54%] IO_1[88.44%] SC_1[75.65%] | vl L:0.252 IO_0[84.89%] IO_1[91.55%] SC_1[82.66%] \n -> No improvement on total (1/25)\nEp 026 | tr L:0.348 IO_0[84.07%] IO_1[88.66%] SC_1[76.43%] | vl L:0.245 IO_0[85.29%] IO_1[91.60%] SC_1[83.47%] \n -> Saved best model (total: 0.2449)\nEp 027 | tr L:0.343 IO_0[84.09%] IO_1[89.07%] SC_1[77.06%] | vl L:0.253 IO_0[85.34%] IO_1[91.95%] SC_1[84.43%] \n -> No improvement on total (1/25)\nEp 028 | tr L:0.341 IO_0[84.31%] IO_1[88.83%] SC_1[76.56%] | vl L:0.221 IO_0[86.15%] IO_1[92.04%] SC_1[85.06%] \n -> Saved best model (total: 0.2213)\nEp 029 | tr L:0.340 IO_0[84.51%] IO_1[89.24%] SC_1[76.91%] | vl L:0.219 IO_0[86.24%] IO_1[92.41%] SC_1[85.41%] \n -> Saved best model (total: 0.2191)\nEp 030 | tr L:0.339 IO_0[84.66%] IO_1[89.36%] SC_1[76.78%] | vl L:0.224 IO_0[86.78%] IO_1[92.36%] SC_1[82.64%] \n -> No improvement on total (1/25)\nEp 031 | tr L:0.331 IO_0[84.92%] IO_1[89.55%] SC_1[77.58%] | vl L:0.210 IO_0[86.82%] IO_1[92.53%] SC_1[86.50%] \n -> Saved best model (total: 0.2102)\nEp 032 | tr L:0.326 IO_0[85.01%] IO_1[89.52%] SC_1[77.74%] | vl L:0.206 IO_0[87.08%] IO_1[92.71%] SC_1[85.92%] \n -> Saved best model (total: 0.2062)\nEp 033 | tr L:0.324 IO_0[84.78%] IO_1[89.52%] SC_1[77.35%] | vl L:0.218 IO_0[86.41%] IO_1[92.60%] SC_1[84.12%] \n -> No improvement on total (1/25)\nEp 034 | tr L:0.326 IO_0[84.93%] IO_1[89.67%] SC_1[77.87%] | vl L:0.225 IO_0[85.68%] IO_1[92.62%] SC_1[84.57%] \n -> No improvement on total (2/25)\nEp 035 | tr L:0.322 IO_0[85.02%] IO_1[89.65%] SC_1[78.16%] | vl L:0.206 IO_0[87.17%] IO_1[92.95%] SC_1[85.99%] \n -> Saved best model (total: 0.2057)\nEp 036 | tr L:0.315 IO_0[85.34%] IO_1[89.69%] SC_1[78.25%] | vl L:0.203 IO_0[87.20%] IO_1[92.85%] SC_1[86.22%] \n -> Saved best model (total: 0.2026)\nEp 037 | tr L:0.316 IO_0[85.10%] IO_1[89.96%] SC_1[78.87%] | vl L:0.203 IO_0[87.20%] IO_1[93.09%] SC_1[86.64%] \n -> No improvement on total (1/25)\nEp 038 | tr L:0.312 IO_0[85.46%] IO_1[90.00%] SC_1[78.60%] | vl L:0.205 IO_0[87.06%] IO_1[92.83%] SC_1[85.45%] \n -> No improvement on total (2/25)\nEp 039 | tr L:0.316 IO_0[85.41%] IO_1[89.85%] SC_1[78.60%] | vl L:0.210 IO_0[87.27%] IO_1[92.62%] SC_1[85.59%] \n -> No improvement on total (3/25)\nEp 040 | tr L:0.318 IO_0[85.49%] IO_1[89.78%] SC_1[78.26%] | vl L:0.207 IO_0[87.31%] IO_1[92.74%] SC_1[84.99%] \n -> No improvement on total (4/25)\nEp 041 | tr L:0.318 IO_0[85.02%] IO_1[89.75%] SC_1[77.90%] | vl L:0.200 IO_0[87.20%] IO_1[92.88%] SC_1[85.96%] \n -> Saved best model (total: 0.1998)\nEp 042 | tr L:0.305 IO_0[85.66%] IO_1[90.15%] SC_1[78.95%] | vl L:0.203 IO_0[86.94%] IO_1[92.83%] SC_1[85.57%] \n -> No improvement on total (1/25)\nEp 043 | tr L:0.308 IO_0[85.61%] IO_1[90.16%] SC_1[79.00%] | vl L:0.199 IO_0[87.62%] IO_1[92.85%] SC_1[86.17%] \n -> Saved best model (total: 0.1992)\nEp 044 | tr L:0.301 IO_0[86.03%] IO_1[90.31%] SC_1[79.21%] | vl L:0.196 IO_0[87.31%] IO_1[93.23%] SC_1[85.64%] \n -> Saved best model (total: 0.1961)\nEp 045 | tr L:0.311 IO_0[85.53%] IO_1[89.99%] SC_1[78.72%] | vl L:0.204 IO_0[87.36%] IO_1[92.92%] SC_1[86.06%] \n -> No improvement on total (1/25)\nEp 046 | tr L:0.312 IO_0[85.83%] IO_1[90.03%] SC_1[78.43%] | vl L:0.208 IO_0[87.43%] IO_1[92.64%] SC_1[85.34%] \n -> No improvement on total (2/25)\nEp 047 | tr L:0.312 IO_0[85.44%] IO_1[90.02%] SC_1[78.38%] | vl L:0.214 IO_0[88.38%] IO_1[92.92%] SC_1[85.92%] \n -> No improvement on total (3/25)\nEp 048 | tr L:0.309 IO_0[85.72%] IO_1[90.32%] SC_1[78.35%] | vl L:0.206 IO_0[87.78%] IO_1[92.88%] SC_1[85.68%] \n -> No improvement on total (4/25)\nEp 049 | tr L:0.301 IO_0[85.98%] IO_1[90.27%] SC_1[78.89%] | vl L:0.195 IO_0[87.83%] IO_1[92.78%] SC_1[85.89%] \n -> Saved best model (total: 0.1948)\nEp 050 | tr L:0.303 IO_0[86.20%] IO_1[90.20%] SC_1[78.95%] | vl L:0.209 IO_0[88.15%] IO_1[93.48%] SC_1[86.24%] \n -> No improvement on total (1/25)\nEp 051 | tr L:0.304 IO_0[86.32%] IO_1[90.22%] SC_1[78.80%] | vl L:0.198 IO_0[88.78%] IO_1[92.74%] SC_1[86.43%] \n -> No improvement on total (2/25)\nEp 052 | tr L:0.294 IO_0[86.26%] IO_1[90.35%] SC_1[79.55%] | vl L:0.208 IO_0[88.01%] IO_1[93.37%] SC_1[86.38%] \n -> No improvement on total (3/25)\nEp 053 | tr L:0.301 IO_0[86.07%] IO_1[90.29%] SC_1[79.26%] | vl L:0.211 IO_0[88.29%] IO_1[93.04%] SC_1[85.08%] \n -> No improvement on total (4/25)\nEp 054 | tr L:0.297 IO_0[86.51%] IO_1[90.43%] SC_1[79.39%] | vl L:0.188 IO_0[89.29%] IO_1[93.99%] SC_1[87.01%] \n -> Saved best model (total: 0.1883)\nEp 055 | tr L:0.282 IO_0[86.76%] IO_1[90.59%] SC_1[79.77%] | vl L:0.184 IO_0[89.01%] IO_1[93.27%] SC_1[87.43%] \n -> Saved best model (total: 0.1840)\nEp 056 | tr L:0.288 IO_0[86.51%] IO_1[90.69%] SC_1[79.54%] | vl L:0.193 IO_0[88.94%] IO_1[93.58%] SC_1[87.27%] \n -> No improvement on total (1/25)\nEp 057 | tr L:0.284 IO_0[86.29%] IO_1[90.69%] SC_1[79.85%] | vl L:0.207 IO_0[88.78%] IO_1[93.23%] SC_1[86.73%] \n -> No improvement on total (2/25)\nEp 058 | tr L:0.279 IO_0[86.73%] IO_1[90.76%] SC_1[79.69%] | vl L:0.180 IO_0[89.20%] IO_1[93.58%] SC_1[87.92%] \n -> Saved best model (total: 0.1804)\nEp 059 | tr L:0.277 IO_0[86.65%] IO_1[90.93%] SC_1[80.38%] | vl L:0.224 IO_0[87.15%] IO_1[92.43%] SC_1[84.85%] \n -> No improvement on total (1/25)\nEp 060 | tr L:0.275 IO_0[86.80%] IO_1[90.94%] SC_1[80.24%] | vl L:0.193 IO_0[89.08%] IO_1[93.55%] SC_1[87.66%] \n -> No improvement on total (2/25)\nEp 061 | tr L:0.280 IO_0[86.71%] IO_1[91.12%] SC_1[79.95%] | vl L:0.186 IO_0[88.69%] IO_1[93.62%] SC_1[88.31%] \n -> No improvement on total (3/25)\nEp 062 | tr L:0.275 IO_0[86.67%] IO_1[90.98%] SC_1[80.18%] | vl L:0.186 IO_0[88.85%] IO_1[94.13%] SC_1[87.31%] \n -> No improvement on total (4/25)\nEp 063 | tr L:0.279 IO_0[86.80%] IO_1[90.81%] SC_1[80.14%] | vl L:0.180 IO_0[88.99%] IO_1[94.48%] SC_1[88.57%] \n -> Saved best model (total: 0.1798)\nEp 064 | tr L:0.276 IO_0[86.59%] IO_1[90.97%] SC_1[80.16%] | vl L:0.173 IO_0[89.08%] IO_1[94.37%] SC_1[88.20%] \n -> Saved best model (total: 0.1732)\nEp 065 | tr L:0.274 IO_0[86.40%] IO_1[91.16%] SC_1[80.85%] | vl L:0.184 IO_0[89.06%] IO_1[93.72%] SC_1[87.50%] \n -> No improvement on total (1/25)\nEp 066 | tr L:0.273 IO_0[86.76%] IO_1[91.05%] SC_1[80.87%] | vl L:0.172 IO_0[89.20%] IO_1[94.55%] SC_1[88.01%] \n -> Saved best model (total: 0.1722)\nEp 067 | tr L:0.265 IO_0[86.81%] IO_1[91.30%] SC_1[81.02%] | vl L:0.179 IO_0[89.15%] IO_1[94.39%] SC_1[88.55%] \n -> No improvement on total (1/25)\nEp 068 | tr L:0.264 IO_0[86.87%] IO_1[91.34%] SC_1[81.01%] | vl L:0.172 IO_0[89.71%] IO_1[93.99%] SC_1[88.52%] \n -> Saved best model (total: 0.1716)\nEp 069 | tr L:0.270 IO_0[86.85%] IO_1[91.08%] SC_1[80.36%] | vl L:0.184 IO_0[88.50%] IO_1[93.99%] SC_1[88.38%] \n -> No improvement on total (1/25)\nEp 070 | tr L:0.257 IO_0[87.14%] IO_1[91.18%] SC_1[81.20%] | vl L:0.179 IO_0[88.69%] IO_1[93.69%] SC_1[87.66%] \n -> No improvement on total (2/25)\nEp 071 | tr L:0.263 IO_0[86.92%] IO_1[91.19%] SC_1[81.50%] | vl L:0.187 IO_0[89.94%] IO_1[94.13%] SC_1[87.45%] \n -> No improvement on total (3/25)\nEp 072 | tr L:0.262 IO_0[87.11%] IO_1[91.57%] SC_1[81.33%] | vl L:0.184 IO_0[89.97%] IO_1[94.18%] SC_1[87.69%] \n -> No improvement on total (4/25)\nEp 073 | tr L:0.259 IO_0[87.06%] IO_1[91.36%] SC_1[81.19%] | vl L:0.174 IO_0[89.59%] IO_1[94.20%] SC_1[89.06%] \n -> No improvement on total (5/25)\nEp 074 | tr L:0.261 IO_0[87.14%] IO_1[91.40%] SC_1[81.14%] | vl L:0.171 IO_0[88.59%] IO_1[94.16%] SC_1[89.20%] \n -> Saved best model (total: 0.1712)\nEp 075 | tr L:0.252 IO_0[87.19%] IO_1[91.63%] SC_1[81.91%] | vl L:0.162 IO_0[90.55%] IO_1[94.69%] SC_1[89.18%] \n -> Saved best model (total: 0.1618)\nEp 076 | tr L:0.256 IO_0[87.51%] IO_1[91.41%] SC_1[81.51%] | vl L:0.192 IO_0[88.13%] IO_1[93.95%] SC_1[87.43%] \n -> No improvement on total (1/25)\nEp 077 | tr L:0.252 IO_0[86.92%] IO_1[91.40%] SC_1[81.82%] | vl L:0.178 IO_0[89.36%] IO_1[94.60%] SC_1[88.90%] \n -> No improvement on total (2/25)\nEp 078 | tr L:0.255 IO_0[87.23%] IO_1[91.51%] SC_1[81.42%] | vl L:0.162 IO_0[90.43%] IO_1[94.93%] SC_1[90.34%] \n -> No improvement on total (3/25)\nEp 079 | tr L:0.248 IO_0[87.27%] IO_1[91.54%] SC_1[81.98%] | vl L:0.167 IO_0[90.43%] IO_1[94.53%] SC_1[89.29%] \n -> No improvement on total (4/25)\nEp 080 | tr L:0.259 IO_0[87.07%] IO_1[91.40%] SC_1[81.35%] | vl L:0.170 IO_0[89.59%] IO_1[94.44%] SC_1[89.76%] \n -> No improvement on total (5/25)\nEp 081 | tr L:0.255 IO_0[87.09%] IO_1[91.66%] SC_1[81.65%] | vl L:0.184 IO_0[89.20%] IO_1[93.95%] SC_1[88.08%] \n -> No improvement on total (6/25)\nEp 082 | tr L:0.253 IO_0[87.05%] IO_1[91.68%] SC_1[81.84%] | vl L:0.194 IO_0[89.78%] IO_1[94.90%] SC_1[87.22%] \n -> No improvement on total (7/25)\nEp 083 | tr L:0.244 IO_0[87.24%] IO_1[91.79%] SC_1[82.08%] | vl L:0.179 IO_0[89.04%] IO_1[94.37%] SC_1[88.11%] \n -> No improvement on total (8/25)\nEp 084 | tr L:0.250 IO_0[86.99%] IO_1[91.72%] SC_1[82.19%] | vl L:0.166 IO_0[90.29%] IO_1[94.76%] SC_1[88.22%] \n -> No improvement on total (9/25)\nEp 085 | tr L:0.252 IO_0[87.03%] IO_1[91.50%] SC_1[81.42%] | vl L:0.174 IO_0[90.29%] IO_1[95.30%] SC_1[89.18%] \n -> No improvement on total (10/25)\nEp 086 | tr L:0.250 IO_0[86.98%] IO_1[91.69%] SC_1[81.58%] | vl L:0.174 IO_0[90.25%] IO_1[95.14%] SC_1[88.41%] \n -> No improvement on total (11/25)\nEp 087 | tr L:0.251 IO_0[87.28%] IO_1[91.71%] SC_1[81.64%] | vl L:0.185 IO_0[88.87%] IO_1[94.16%] SC_1[87.90%] \n -> No improvement on total (12/25)\nEp 088 | tr L:0.248 IO_0[87.31%] IO_1[91.36%] SC_1[82.12%] | vl L:0.161 IO_0[90.83%] IO_1[95.09%] SC_1[90.22%] \n -> Saved best model (total: 0.1613)\nEp 089 | tr L:0.256 IO_0[86.99%] IO_1[91.48%] SC_1[81.84%] | vl L:0.163 IO_0[90.04%] IO_1[94.86%] SC_1[88.22%] \n -> No improvement on total (1/25)\nEp 090 | tr L:0.249 IO_0[87.25%] IO_1[91.84%] SC_1[81.99%] | vl L:0.174 IO_0[89.41%] IO_1[93.95%] SC_1[86.85%] \n -> No improvement on total (2/25)\nEp 091 | tr L:0.245 IO_0[86.75%] IO_1[92.04%] SC_1[82.23%] | vl L:0.172 IO_0[89.43%] IO_1[94.74%] SC_1[88.94%] \n -> No improvement on total (3/25)\nEp 092 | tr L:0.245 IO_0[87.40%] IO_1[91.58%] SC_1[81.98%] | vl L:0.164 IO_0[90.06%] IO_1[95.07%] SC_1[89.73%] \n -> No improvement on total (4/25)\nEp 093 | tr L:0.248 IO_0[87.30%] IO_1[91.68%] SC_1[82.20%] | vl L:0.168 IO_0[90.50%] IO_1[94.76%] SC_1[89.04%] \n -> No improvement on total (5/25)\nEp 094 | tr L:0.245 IO_0[87.25%] IO_1[91.95%] SC_1[82.57%] | vl L:0.162 IO_0[91.11%] IO_1[95.30%] SC_1[89.34%] \n -> No improvement on total (6/25)\nEp 095 | tr L:0.238 IO_0[87.23%] IO_1[91.72%] SC_1[82.82%] | vl L:0.152 IO_0[91.48%] IO_1[95.11%] SC_1[90.53%] \n -> Saved best model (total: 0.1518)\nEp 096 | tr L:0.243 IO_0[87.66%] IO_1[91.98%] SC_1[82.57%] | vl L:0.174 IO_0[90.11%] IO_1[94.88%] SC_1[89.11%] \n -> No improvement on total (1/25)\nEp 097 | tr L:0.241 IO_0[87.22%] IO_1[91.61%] SC_1[82.14%] | vl L:0.167 IO_0[89.71%] IO_1[94.44%] SC_1[88.99%] \n -> No improvement on total (2/25)\nEp 098 | tr L:0.245 IO_0[87.49%] IO_1[91.76%] SC_1[82.51%] | vl L:0.162 IO_0[90.13%] IO_1[94.76%] SC_1[89.25%] \n -> No improvement on total (3/25)\nEp 099 | tr L:0.247 IO_0[87.01%] IO_1[91.65%] SC_1[82.12%] | vl L:0.159 IO_0[90.27%] IO_1[95.11%] SC_1[89.57%] \n -> No improvement on total (4/25)\nEp 100 | tr L:0.248 IO_0[87.05%] IO_1[91.80%] SC_1[82.10%] | vl L:0.158 IO_0[90.88%] IO_1[95.34%] SC_1[89.48%] \n -> No improvement on total (5/25)\nEND RUN: LR_0.0004_WD_0.0001_SCH_cosine_X1 | best total: 0.1518\nHyperparameter tuning completed.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"plot_data = []\n\nfor run_name, history in all_histories.items():\n    for ep in history:\n        ep[\"run_name\"] = run_name\n        plot_data.append(ep)\n\ndf = pd.DataFrame(plot_data)\n\ndf[\"tr_scene_avg\"] = df[\"tr_total\"]\ndf[\"vl_scene_avg\"] = df[\"vl_total\"]\n\nrun_names = df[\"run_name\"].unique()\nn_runs = len(run_names)\n\n# ------------------------------------ #\n# 1.  LOSS curves (classification)      #\n# ------------------------------------ #\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n# Define custom colors for training and validation lines\ntrain_color = \"blue\"  # Color for training loss lines\nval_color = \"green\"    # Color for validation loss lines\n\nfig, ax1 = plt.subplots(figsize=(15, 8))\n\n# Plot training loss with a specific color\nsns.lineplot(\n    data=df,\n    x=\"epoch\",\n    y=\"tr_total\",\n    hue=\"run_name\",\n    style=\"run_name\",\n    dashes=True,\n    palette={run: train_color for run in df[\"run_name\"].unique()},  # Assign single color to all runs\n    ax=ax1,\n    legend=False,\n    markersize=7\n)\n\n# Plot validation loss with a different color\nsns.lineplot(\n    data=df,\n    x=\"epoch\",\n    y=\"vl_total\",\n    hue=\"run_name\",\n    style=\"run_name\",\n    dashes={r: (2, 2) for r in run_names},  # Dashed for validation\n    palette={run: val_color for run in df[\"run_name\"].unique()},  # Assign single color to all runs\n    ax=ax1,\n    legend=False\n)\n\nax1.set(\n    title=\"Classification-loss trend per run\",\n    xlabel=\"Epoch\",\n    ylabel=\"Loss\"\n)\nax1.legend(title=\"run\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\nplt.tight_layout(rect=[0, 0, 0.82, 1])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:33:40.287647Z","iopub.execute_input":"2025-09-03T15:33:40.288694Z","iopub.status.idle":"2025-09-03T15:33:40.723748Z","shell.execute_reply.started":"2025-09-03T15:33:40.288661Z","shell.execute_reply":"2025-09-03T15:33:40.723102Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x800 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Load model properly\nBEST_MODEL_PATH = \"/kaggle/working/validation_runs/LR_0.0004_WD_0.0001_SCH_cosine_X1/best_model.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T09:59:31.113562Z","iopub.execute_input":"2025-09-04T09:59:31.114273Z","iopub.status.idle":"2025-09-04T09:59:31.117467Z","shell.execute_reply.started":"2025-09-04T09:59:31.114246Z","shell.execute_reply":"2025-09-04T09:59:31.116709Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom collections import defaultdict\n\n@torch.no_grad()\ndef evaluate_model_comprehensive(model, loader, battery_level, apply_posthoc_rule=True, verbose=True):\n    \"\"\"\n    Comprehensive evaluation with:\n    1. Bug fixes from original code\n    2. Per-class analysis \n    3. Confidence distribution analysis\n    4. Label encoder verification\n    5. Distribution shift detection\n    \"\"\"\n    device = next(model.parameters()).device\n    model.eval()\n\n    # ---------------- Verify label encoders ----------------\n    test_io_classes = list(loader.dataset.io_label_encoder.classes_)\n    test_scene_classes = list(loader.dataset.scene_label_encoder.classes_)\n    \n    # Load training classes from checkpoint for comparison\n    try:\n        ckpt = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\n        train_io_classes = ckpt.get(\"io_classes\", test_io_classes)\n        train_scene_classes = ckpt.get(\"scene_classes\", test_scene_classes)\n        \n        if train_io_classes != test_io_classes:\n            print(\"⚠️  WARNING: I/O label encoders don't match!\")\n            print(f\"Train: {train_io_classes}\")\n            print(f\"Test:  {test_io_classes}\")\n            \n        if train_scene_classes != test_scene_classes:\n            print(\"⚠️  WARNING: Scene label encoders don't match!\")\n            print(f\"Train: {train_scene_classes}\")\n            print(f\"Test:  {test_scene_classes}\")\n    except:\n        print(\"⚠️  Could not verify label encoder consistency\")\n\n    # ---------------- Initialize counters ----------------\n    total_samples_count = 0\n    exit1_count = 0\n    exit2_count = 0\n    \n    # Overall accuracy counters\n    correct_io_exit1_count = 0\n    correct_io_exit2_final_count = 0  \n    correct_scene_exit2_count = 0\n    \n    # Per-class tracking\n    io_class_stats = defaultdict(lambda: {'total': 0, 'correct': 0})\n    scene_class_stats = defaultdict(lambda: {'total': 0, 'correct': 0})\n    \n    # Confidence tracking\n    confidence_by_class = defaultdict(list)\n    confidence_by_exit = {'exit1': [], 'exit2': []}\n    \n    # F1 score lists\n    io_true_all, io_pred_final_all = [], []\n    io_true_exit2, io_pred_exit2_final = [], []\n    io_true_exit2_e0, io_pred_exit2_e0 = [], []\n    scene_true_exit2, scene_pred_exit2_raw = [], []\n    scene_true_exit2_final, scene_pred_exit2_final = [], []\n    \n    # Label mapping setup\n    scene_encoder = loader.dataset.scene_label_encoder\n    io_encoder = loader.dataset.io_label_encoder\n    \n    try:\n        street_label_int = list(scene_encoder.classes_).index('Street')\n        outdoor_label_int = list(io_encoder.classes_).index('Outdoor')\n    except ValueError as e:\n        print(f\"⚠️  Label mapping error: {e}\")\n        street_label_int = 0\n        outdoor_label_int = 0\n\n    # Depth permission\n    try:\n        is_deep_allowed = (allowed_depth(battery_level) != 1)\n    except Exception:\n        is_deep_allowed = True\n\n    # -------------------------- Main evaluation loop --------------------------\n    for feats, io_labels, scene_labels in loader:\n        feats = feats.to(device, non_blocking=True).float()\n        io_labels = io_labels.view(-1).to(device).long()\n        scene_labels = scene_labels.view(-1).to(device).long()\n        batch_size = feats.size(0)\n        total_samples_count += batch_size\n\n        # Get all outputs\n        prev_flag = getattr(model, \"if_train\", False)\n        model.if_train = True\n        batt_vec = torch.full((batch_size,), float(battery_level), device=device)\n        outputs, _ = model(feats, battery_level=batt_vec)\n        model.if_train = prev_flag\n\n        if len(outputs) < 2:\n            raise RuntimeError(\"Model must return at least [e0_io_logits, e1_scene_logits]\")\n\n        e0_io_logits = outputs[0]\n        e1_scene_logits = outputs[1]\n        e1_io_logits = outputs[2] if len(outputs) > 2 else None\n\n        # ---------- Routing decision ----------\n        early_confidence = F.softmax(e0_io_logits, dim=-1).amax(dim=-1)\n        \n        try:\n            tau_value = tau_sigmoid(battery_level)  # Use your tau_sigmoid instead of tau_piecewise\n            tau_value = float(tau_value.item()) if hasattr(tau_value, \"item\") else float(tau_value)\n        except Exception:\n            tau_value = 0.9\n\n        go_deep_mask = (early_confidence < tau_value) & is_deep_allowed\n        exit_early_mask = ~go_deep_mask\n\n        exit1_count += int(exit_early_mask.sum().item())\n        exit2_count += int(go_deep_mask.sum().item())\n\n        # ---------- Predictions ----------\n        e0_io_pred = e0_io_logits.argmax(dim=1)\n        \n        if e1_io_logits is not None:\n            e1_io_pred = e1_io_logits.argmax(dim=1)\n        else:\n            e1_io_pred = e0_io_pred\n\n        io_final_pred = torch.where(go_deep_mask, e1_io_pred, e0_io_pred)\n        \n        # Scene predictions (raw and with post-hoc rule)\n        scene_pred_raw = e1_scene_logits.argmax(dim=1)\n        scene_pred_final = scene_pred_raw.clone()\n        \n        if apply_posthoc_rule:\n            # Apply Outdoor->Street mapping\n            outdoor_mask = (io_final_pred == outdoor_label_int)\n            scene_pred_final[outdoor_mask] = street_label_int\n\n        # ---------- Confidence tracking ----------\n        for i in range(batch_size):\n            conf = early_confidence[i].item()\n            io_class = io_encoder.classes_[io_labels[i]]\n            confidence_by_class[io_class].append(conf)\n            \n            if exit_early_mask[i]:\n                confidence_by_exit['exit1'].append(conf)\n            else:\n                confidence_by_exit['exit2'].append(conf)\n\n        # ---------- Accuracy computation ----------\n        # Early exit I/O accuracy\n        if exit_early_mask.any():\n            early_correct = (e0_io_pred[exit_early_mask] == io_labels[exit_early_mask])\n            correct_io_exit1_count += early_correct.sum().item()\n            \n            # Per-class stats for early exit\n            for i in torch.where(exit_early_mask)[0]:\n                io_class = io_encoder.classes_[io_labels[i]]\n                io_class_stats[io_class]['total'] += 1\n                if early_correct[exit_early_mask.cumsum(0)[i] - 1]:  # Adjust index\n                    io_class_stats[io_class]['correct'] += 1\n\n        # Late exit accuracies\n        if go_deep_mask.any():\n            # I/O accuracy on late subset\n            late_io_correct = (io_final_pred[go_deep_mask] == io_labels[go_deep_mask])\n            correct_io_exit2_final_count += late_io_correct.sum().item()\n            \n            # Scene accuracy on late subset  \n            late_scene_correct = (scene_pred_final[go_deep_mask] == scene_labels[go_deep_mask])\n            correct_scene_exit2_count += late_scene_correct.sum().item()\n            \n            # Per-class stats for late samples\n            late_indices = torch.where(go_deep_mask)[0]\n            for i, late_idx in enumerate(late_indices):\n                # I/O class stats\n                io_class = io_encoder.classes_[io_labels[late_idx]]\n                io_class_stats[io_class]['total'] += 1\n                if late_io_correct[i]:\n                    io_class_stats[io_class]['correct'] += 1\n                \n                # Scene class stats\n                scene_class = scene_encoder.classes_[scene_labels[late_idx]]\n                scene_class_stats[scene_class]['total'] += 1\n                if late_scene_correct[i]:\n                    scene_class_stats[scene_class]['correct'] += 1\n\n            # Collect for F1 scores\n            io_true_exit2.extend(io_labels[go_deep_mask].tolist())\n            io_pred_exit2_final.extend(io_final_pred[go_deep_mask].tolist())\n            io_true_exit2_e0.extend(io_labels[go_deep_mask].tolist())\n            io_pred_exit2_e0.extend(e0_io_pred[go_deep_mask].tolist())\n            \n            scene_true_exit2.extend(scene_labels[go_deep_mask].tolist())\n            scene_pred_exit2_raw.extend(scene_pred_raw[go_deep_mask].tolist())\n            scene_true_exit2_final.extend(scene_labels[go_deep_mask].tolist())\n            scene_pred_exit2_final.extend(scene_pred_final[go_deep_mask].tolist())\n\n        # Overall I/O for F1\n        io_true_all.extend(io_labels.tolist())\n        io_pred_final_all.extend(io_final_pred.tolist())\n        \n        # Per-class I/O stats for all samples (update totals for early samples above)\n        for i in range(batch_size):\n            if not go_deep_mask[i]:  # Early exit samples not yet counted\n                continue  # Already handled above\n\n    # -------------------------- Final computations --------------------------\n    total = total_samples_count\n    \n    # Accuracy rates\n    acc_io_exit1 = (correct_io_exit1_count / exit1_count) if exit1_count else 0.0\n    acc_io_exit2_final = (correct_io_exit2_final_count / exit2_count) if exit2_count else 0.0  \n    acc_scene_exit2 = (correct_scene_exit2_count / exit2_count) if exit2_count else 0.0\n\n    # F1 scores\n    f1_io_final_all = f1_score(io_true_all, io_pred_final_all, average='weighted', zero_division=0) if io_true_all else 0.0\n    f1_io_exit2_final = f1_score(io_true_exit2, io_pred_exit2_final, average='weighted', zero_division=0) if io_true_exit2 else 0.0\n    f1_io_exit2_e0 = f1_score(io_true_exit2_e0, io_pred_exit2_e0, average='weighted', zero_division=0) if io_true_exit2_e0 else 0.0\n    f1_scene_exit2_raw = f1_score(scene_true_exit2, scene_pred_exit2_raw, average='weighted', zero_division=0) if scene_true_exit2 else 0.0\n    f1_scene_exit2_final = f1_score(scene_true_exit2_final, scene_pred_exit2_final, average='weighted', zero_division=0) if scene_true_exit2_final else 0.0\n\n    # Per-class accuracies\n    io_class_accuracies = {}\n    scene_class_accuracies = {}\n    \n    for cls, stats in io_class_stats.items():\n        io_class_accuracies[cls] = stats['correct'] / stats['total'] if stats['total'] > 0 else 0.0\n        \n    for cls, stats in scene_class_stats.items():\n        scene_class_accuracies[cls] = stats['correct'] / stats['total'] if stats['total'] > 0 else 0.0\n\n    # Confidence statistics\n    confidence_stats = {}\n    for cls, confs in confidence_by_class.items():\n        if confs:\n            confidence_stats[cls] = {\n                'mean': np.mean(confs),\n                'std': np.std(confs),\n                'min': np.min(confs),\n                'max': np.max(confs)\n            }\n\n    exit_confidence_stats = {}\n    for exit_name, confs in confidence_by_exit.items():\n        if confs:\n            exit_confidence_stats[exit_name] = {\n                'mean': np.mean(confs),\n                'std': np.std(confs),\n                'count': len(confs)\n            }\n\n    results = {\n        \"battery_level\": battery_level,\n        \"coverage\": {\n            \"exit1_pct\": (exit1_count / total * 100.0) if total else 0.0,\n            \"exit2_pct\": (exit2_count / total * 100.0) if total else 0.0,\n        },\n        \"accuracy\": {\n            \"io_exit1\": acc_io_exit1,\n            \"io_exit2_final\": acc_io_exit2_final,\n            \"scene_exit2\": acc_scene_exit2,\n        },\n        \"per_class_accuracy\": {\n            \"io\": io_class_accuracies,\n            \"scene\": scene_class_accuracies\n        },\n        \"per_class_counts\": {\n            \"io\": dict(io_class_stats),\n            \"scene\": dict(scene_class_stats)\n        },\n        \"f1_weighted\": {\n            \"io_final_all\": f1_io_final_all,\n            \"io_exit2_final\": f1_io_exit2_final,\n            \"io_exit2_e0_baseline\": f1_io_exit2_e0,\n            \"scene_exit2_raw\": f1_scene_exit2_raw,\n            \"scene_exit2_final\": f1_scene_exit2_final,\n        },\n        \"confidence_analysis\": {\n            \"by_class\": confidence_stats,\n            \"by_exit\": exit_confidence_stats,\n            \"threshold_used\": tau_value\n        },\n        \"counts\": {\n            \"total\": total,\n            \"exit1\": exit1_count,\n            \"exit2\": exit2_count,\n        }\n    }\n\n    # Verbose reporting\n    if verbose:\n        print_detailed_results(results)\n\n    return results\n\ndef print_detailed_results(results):\n    \"\"\"Print comprehensive results with distribution analysis\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"COMPREHENSIVE EVALUATION @ Battery Level {results['battery_level']:.2f}\")\n    print(f\"{'='*70}\")\n    \n    # Coverage\n    coverage = results['coverage']\n    print(f\"\\n📊 Exit Coverage:\")\n    print(f\"  Exit 1 (Early): {coverage['exit1_pct']:.1f}% ({results['counts']['exit1']} samples)\")\n    print(f\"  Exit 2 (Late):  {coverage['exit2_pct']:.1f}% ({results['counts']['exit2']} samples)\")\n    \n    # Overall accuracy\n    acc = results['accuracy']\n    print(f\"\\n🎯 Overall Accuracy:\")\n    print(f\"  I/O @ Exit 1:     {acc['io_exit1']:.3f}\")\n    print(f\"  I/O @ Exit 2:     {acc['io_exit2_final']:.3f}\")\n    print(f\"  Scene @ Exit 2:   {acc['scene_exit2']:.3f}\")\n    \n    # Per-class breakdown\n    print(f\"\\n📋 Per-Class I/O Accuracy:\")\n    io_acc = results['per_class_accuracy']['io']\n    io_counts = results['per_class_counts']['io']\n    for cls in sorted(io_acc.keys()):\n        acc_val = io_acc[cls]\n        counts = io_counts[cls]\n        print(f\"  {cls:>8}: {acc_val:.3f} ({counts['correct']:>4}/{counts['total']:>4})\")\n    \n    if results['per_class_accuracy']['scene']:\n        print(f\"\\n📋 Per-Class Scene Accuracy:\")\n        scene_acc = results['per_class_accuracy']['scene']  \n        scene_counts = results['per_class_counts']['scene']\n        for cls in sorted(scene_acc.keys()):\n            acc_val = scene_acc[cls]\n            counts = scene_counts[cls]\n            print(f\"  {cls:>8}: {acc_val:.3f} ({counts['correct']:>4}/{counts['total']:>4})\")\n    \n    # Confidence analysis\n    conf_analysis = results['confidence_analysis']\n    print(f\"\\n🎲 Confidence Analysis (Threshold: {conf_analysis['threshold_used']:.3f}):\")\n    \n    if 'by_class' in conf_analysis:\n        print(\"  By Class:\")\n        for cls, stats in conf_analysis['by_class'].items():\n            print(f\"    {cls:>8}: μ={stats['mean']:.3f}, σ={stats['std']:.3f}\")\n    \n    if 'by_exit' in conf_analysis:\n        print(\"  By Exit:\")\n        for exit_name, stats in conf_analysis['by_exit'].items():\n            print(f\"    {exit_name:>8}: μ={stats['mean']:.3f}, σ={stats['std']:.3f}, n={stats['count']}\")\n    \n    # F1 scores\n    f1 = results['f1_weighted']\n    print(f\"\\n🏆 Weighted F1 Scores:\")\n    print(f\"  I/O (All samples):     {f1['io_final_all']:.3f}\")\n    print(f\"  I/O (Late final):      {f1['io_exit2_final']:.3f}\")  \n    print(f\"  I/O (Late E0 baseline): {f1['io_exit2_e0_baseline']:.3f}\")\n    print(f\"  Scene (Raw):           {f1['scene_exit2_raw']:.3f}\")\n    print(f\"  Scene (Final):         {f1['scene_exit2_final']:.3f}\")\n\n# Fixed usage code\ndef run_comprehensive_evaluation():\n    \"\"\"Run the comprehensive evaluation with proper error handling\"\"\"\n    try:\n        ckpt = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\n        print(f\"✅ Successfully loaded checkpoint from {BEST_MODEL_PATH}\")\n        \n        model = DepthwiseEarlyExitCNN1D(\n            if_train=False,\n            train_shape=ckpt.get(\"train_shape\", train_loader.dataset[0][0].shape),\n            n_io=len(ckpt.get(\"io_classes\", train_dataset.io_label_encoder.classes_)),\n            n_scene=len(ckpt.get(\"scene_classes\", train_dataset.scene_label_encoder.classes_))\n        ).to(device)\n\n        state = ckpt[\"model\"] if \"model\" in ckpt else ckpt\n        model.load_state_dict(state, strict=True)\n        print(f\"✅ Model loaded with {sum(p.numel() for p in model.parameters()):,} parameters\")\n        \n    except Exception as e:\n        print(f\"❌ Error loading model: {e}\")\n        return\n\n    # Test at multiple battery levels\n    battery_levels = np.linspace(0.1, 1.0, 10) # Crea 10 punti da 0.1 a 1.0\n    for battery_level in battery_levels:\n        try:\n            results = evaluate_model_comprehensive(\n                model, test_loader, battery_level, \n                apply_posthoc_rule=True, verbose=True\n            )\n            print(f\"\\n{'='*70}\\n\")\n            \n        except Exception as e:\n            print(f\"❌ Error during evaluation at battery {battery_level}: {e}\")\n            import traceback\n            traceback.print_exc()\n\n# Run the evaluation\nrun_comprehensive_evaluation()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:35:29.239256Z","iopub.execute_input":"2025-09-03T15:35:29.239534Z","iopub.status.idle":"2025-09-03T15:40:05.814576Z","shell.execute_reply.started":"2025-09-03T15:35:29.239516Z","shell.execute_reply":"2025-09-03T15:40:05.813664Z"}},"outputs":[{"name":"stdout","text":"✅ Successfully loaded checkpoint from /kaggle/working/validation_runs/LR_0.0004_WD_0.0001_SCH_cosine_X1/best_model.pth\n✅ Model loaded with 7,019 parameters\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.10\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.869\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.909 (3462/3809)\n   Outdoor: 0.770 (1181/1533)\n\n🎲 Confidence Analysis (Threshold: 0.803):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.824, σ=0.123, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.869\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.20\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 64.8% (3462 samples)\n  Exit 2 (Late):  35.2% (1880 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.945\n  I/O @ Exit 2:     0.805\n  Scene @ Exit 2:   0.666\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.916 (3489/3809)\n   Outdoor: 0.845 (1295/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.692 ( 313/ 452)\n   Hallway: 0.646 ( 314/ 486)\n    Office: 0.367 ( 109/ 297)\n    Street: 0.802 ( 517/ 645)\n\n🎲 Confidence Analysis (Threshold: 0.809):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.902, σ=0.044, n=3462\n       exit2: μ=0.680, σ=0.088, n=1880\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.896\n  I/O (Late final):      0.808\n  I/O (Late E0 baseline): 0.731\n  Scene (Raw):           0.684\n  Scene (Final):         0.665\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.30\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 61.9% (3309 samples)\n  Exit 2 (Late):  38.1% (2033 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.946\n  I/O @ Exit 2:     0.813\n  Scene @ Exit 2:   0.672\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.916 (3489/3809)\n   Outdoor: 0.845 (1295/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.710 ( 348/ 490)\n   Hallway: 0.665 ( 345/ 519)\n    Office: 0.383 ( 132/ 345)\n    Street: 0.797 ( 541/ 679)\n\n🎲 Confidence Analysis (Threshold: 0.821):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.906, σ=0.041, n=3309\n       exit2: μ=0.690, σ=0.092, n=2033\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.896\n  I/O (Late final):      0.816\n  I/O (Late E0 baseline): 0.744\n  Scene (Raw):           0.688\n  Scene (Final):         0.671\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.40\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 55.2% (2950 samples)\n  Exit 2 (Late):  44.8% (2392 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.953\n  I/O @ Exit 2:     0.827\n  Scene @ Exit 2:   0.683\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.917 (3492/3809)\n   Outdoor: 0.845 (1296/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.725 ( 429/ 592)\n   Hallway: 0.676 ( 396/ 586)\n    Office: 0.444 ( 199/ 448)\n    Street: 0.795 ( 609/ 766)\n\n🎲 Confidence Analysis (Threshold: 0.848):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.914, σ=0.034, n=2950\n       exit2: μ=0.712, σ=0.099, n=2392\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.897\n  I/O (Late final):      0.829\n  I/O (Late E0 baseline): 0.766\n  Scene (Raw):           0.698\n  Scene (Final):         0.683\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.50\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 42.0% (2246 samples)\n  Exit 2 (Late):  58.0% (3096 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.968\n  I/O @ Exit 2:     0.845\n  Scene @ Exit 2:   0.710\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.917 (3491/3809)\n   Outdoor: 0.847 (1298/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.697 ( 498/ 714)\n   Hallway: 0.711 ( 508/ 714)\n    Office: 0.637 ( 470/ 738)\n    Street: 0.775 ( 721/ 930)\n\n🎲 Confidence Analysis (Threshold: 0.890):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.928, σ=0.027, n=2246\n       exit2: μ=0.748, σ=0.110, n=3096\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.897\n  I/O (Late final):      0.846\n  I/O (Late E0 baseline): 0.796\n  Scene (Raw):           0.726\n  Scene (Final):         0.715\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.60\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 15.2% (812 samples)\n  Exit 2 (Late):  84.8% (4530 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.972\n  I/O @ Exit 2:     0.884\n  Scene @ Exit 2:   0.763\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.918 (3495/3809)\n   Outdoor: 0.847 (1298/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.645 ( 522/ 809)\n   Hallway: 0.744 ( 700/ 941)\n    Office: 0.808 (1337/1655)\n    Street: 0.796 ( 896/1125)\n\n🎲 Confidence Analysis (Threshold: 0.932):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.958, σ=0.019, n=812\n       exit2: μ=0.799, σ=0.119, n=4530\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.898\n  I/O (Late final):      0.885\n  I/O (Late E0 baseline): 0.850\n  Scene (Raw):           0.777\n  Scene (Final):         0.769\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.70\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 6.2% (330 samples)\n  Exit 2 (Late):  93.8% (5012 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.973\n  I/O @ Exit 2:     0.892\n  Scene @ Exit 2:   0.776\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.918 (3495/3809)\n   Outdoor: 0.847 (1298/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.636 ( 525/ 825)\n   Hallway: 0.745 ( 783/1051)\n    Office: 0.829 (1556/1878)\n    Street: 0.816 (1027/1258)\n\n🎲 Confidence Analysis (Threshold: 0.959):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.978, σ=0.011, n=330\n       exit2: μ=0.813, σ=0.120, n=5012\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.898\n  I/O (Late final):      0.893\n  I/O (Late E0 baseline): 0.862\n  Scene (Raw):           0.790\n  Scene (Final):         0.782\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.80\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 4.2% (222 samples)\n  Exit 2 (Late):  95.8% (5120 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.973\n  I/O @ Exit 2:     0.894\n  Scene @ Exit 2:   0.780\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.918 (3495/3809)\n   Outdoor: 0.847 (1298/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.635 ( 526/ 828)\n   Hallway: 0.748 ( 807/1079)\n    Office: 0.829 (1562/1884)\n    Street: 0.826 (1098/1329)\n\n🎲 Confidence Analysis (Threshold: 0.971):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.985, σ=0.007, n=222\n       exit2: μ=0.817, σ=0.121, n=5120\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.898\n  I/O (Late final):      0.895\n  I/O (Late E0 baseline): 0.864\n  Scene (Raw):           0.793\n  Scene (Final):         0.785\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 3.5% (187 samples)\n  Exit 2 (Late):  96.5% (5155 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.979\n  I/O @ Exit 2:     0.894\n  Scene @ Exit 2:   0.781\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.918 (3495/3809)\n   Outdoor: 0.847 (1298/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.635 ( 526/ 828)\n   Hallway: 0.748 ( 812/1086)\n    Office: 0.829 (1562/1884)\n    Street: 0.830 (1126/1357)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.987, σ=0.006, n=187\n       exit2: μ=0.818, σ=0.121, n=5155\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.898\n  I/O (Late final):      0.895\n  I/O (Late E0 baseline): 0.865\n  Scene (Raw):           0.794\n  Scene (Final):         0.786\n\n======================================================================\n\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 1.00\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 3.2% (169 samples)\n  Exit 2 (Late):  96.8% (5173 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.982\n  I/O @ Exit 2:     0.894\n  Scene @ Exit 2:   0.782\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.918 (3495/3809)\n   Outdoor: 0.847 (1298/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.635 ( 526/ 828)\n   Hallway: 0.747 ( 813/1088)\n    Office: 0.829 (1562/1884)\n    Street: 0.832 (1142/1373)\n\n🎲 Confidence Analysis (Threshold: 0.979):\n  By Class:\n      Indoor: μ=0.827, σ=0.115\n     Outdoor: μ=0.814, σ=0.142\n  By Exit:\n       exit1: μ=0.988, σ=0.005, n=169\n       exit2: μ=0.818, σ=0.122, n=5173\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.898\n  I/O (Late final):      0.895\n  I/O (Late E0 baseline): 0.865\n  Scene (Raw):           0.795\n  Scene (Final):         0.787\n\n======================================================================\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"@torch.no_grad()\ndef get_exit_rate_at_battery_level(model, loader, battery_level: float):\n    \"\"\"\n    Funzione semplificata per calcolare il solo Early Exit Rate a un dato livello di batteria.\n    Utilizza la nuova funzione tau_sigmoid che dovrebbe essere nel forward del modello.\n    \"\"\"\n    device = next(model.parameters()).device\n    model.eval()\n    model.if_train = False # Assicura che il modello usi la logica di inferenza\n\n    total_samples = 0\n    exit1_samples = 0\n    \n    # Assumiamo che il forward del modello usi tau_sigmoid\n    # e restituisca (outputs, exit_id) durante l'inferenza\n    for feats, _, _ in loader:\n        feats = feats.to(device, non_blocking=True).float()\n        batch_size = feats.size(0)\n        \n        # Per coerenza, passiamo un tensore di batteria, anche se il valore è lo stesso\n        batt_vec = torch.full((batch_size,), battery_level, device=device)\n\n        # Il tuo modello in modalità inferenza (if_train=False) dovrebbe restituire l'ID dell'uscita\n        outputs, exit_ids = model(feats, battery_level=batt_vec)\n        \n        # Gestiamo il caso in cui l'ID di uscita è un tensore o uno scalare\n        if torch.is_tensor(exit_ids):\n             # Se ogni campione ha la sua decisione (più granulare)\n            exit1_samples += (exit_ids == 1).sum().item()\n        else:\n            # Se l'intero batch ha una sola decisione\n            if exit_ids == 1:\n                exit1_samples += batch_size\n\n        total_samples += batch_size\n        \n    if total_samples == 0:\n        return 0.0\n        \n    return (exit1_samples / total_samples) * 100.0\n\nckpt = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\nprint(f\"✅ Successfully loaded checkpoint from {BEST_MODEL_PATH}\")\n\nmodel = DepthwiseEarlyExitCNN1D(\n    if_train=False,\n    train_shape=ckpt.get(\"train_shape\", train_loader.dataset[0][0].shape),\n    n_io=len(ckpt.get(\"io_classes\", train_dataset.io_label_encoder.classes_)),\n    n_scene=len(ckpt.get(\"scene_classes\", train_dataset.scene_label_encoder.classes_))\n).to(device)\n\nstate = ckpt[\"model\"] if \"model\" in ckpt else ckpt\nmodel.load_state_dict(state, strict=True)\nprint(f\"✅ Model loaded with {sum(p.numel() for p in model.parameters()):,} parameters\")\n\nbattery_levels = np.linspace(0.1, 1.0, 30) # Crea 10 punti da 0.1 a 1.0\nexit_rates = []\n\nprint(\"Inizio valutazione per il grafico...\")\nfor level in battery_levels:\n    rate = get_exit_rate_at_battery_level(model, test_loader, level)\n    exit_rates.append(rate)\n    print(f\"  Batteria: {level:.2f} -> Early Exit Rate: {rate:.2f}%\")\nprint(\"Valutazione completata.\")\n\n\n# --- 2. Creazione del Grafico ---\nsns.set(style=\"whitegrid\", context=\"notebook\")\nplt.figure(figsize=(10, 6))\n\n# Plot dei dati\nplt.plot(battery_levels, exit_rates, marker='o', linestyle='-', color='b', label='Tasso di Early Exit')\n\n# Abbellimento del grafico\nplt.title('Tasso di Early Exit in Funzione del Livello della Batteria', fontsize=16)\nplt.xlabel('Livello Batteria', fontsize=12)\nplt.ylabel('Early Exit Rate (%)', fontsize=12)\nplt.xlim(0, 1.1)\nplt.ylim(0, 105)\nplt.xticks(np.arange(0, 1.1, 0.1))\nplt.yticks(np.arange(0, 101, 10))\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.legend()\nplt.tight_layout()\n\n# Mostra il grafico\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:02:42.862307Z","iopub.execute_input":"2025-09-04T10:02:42.862612Z","iopub.status.idle":"2025-09-04T10:02:51.245246Z","shell.execute_reply.started":"2025-09-04T10:02:42.862588Z","shell.execute_reply":"2025-09-04T10:02:51.244231Z"}},"outputs":[{"name":"stdout","text":"✅ Successfully loaded checkpoint from /kaggle/working/validation_runs/LR_0.0004_WD_0.0001_SCH_cosine_X1/best_model.pth\n✅ Model loaded with 7,019 parameters\nInizio valutazione per il grafico...\n","output_type":"stream"},{"name":"stderr","text":"Exception in thread Thread-5 (_pin_memory_loop):\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n    self.run()\n  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n    do_one_step()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n    fd = df.detach()\n         ^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n    with _resource_sharer.get_connection(self._id) as conn:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n    c = Client(address, authkey=process.current_process().authkey)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n    c = SocketClient(address)\n        ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n    s.connect(address)\nFileNotFoundError: [Errno 2] No such file or directory\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3262786420.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inizio valutazione per il grafico...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbattery_levels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exit_rate_at_battery_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mexit_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Batteria: {level:.2f} -> Early Exit Rate: {rate:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3262786420.py\u001b[0m in \u001b[0;36mget_exit_rate_at_battery_level\u001b[0;34m(model, loader, battery_level)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Assumiamo che il forward del modello usi tau_sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# e restituisca (outputs, exit_id) durante l'inferenza\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"def count_parameters(model):\n    \"\"\"Counts the total number of trainable parameters in a PyTorch model.\"\"\"\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nckpt = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\nprint(f\"✅ Successfully loaded checkpoint from {BEST_MODEL_PATH}\")\n\nmodel = DepthwiseEarlyExitCNN1D(\n    if_train=False,\n    train_shape=ckpt.get(\"train_shape\", train_loader.dataset[0][0].shape),\n    n_io=len(ckpt.get(\"io_classes\", train_dataset.io_label_encoder.classes_)),\n    n_scene=len(ckpt.get(\"scene_classes\", train_dataset.scene_label_encoder.classes_))\n).to(device)\n\nstate = ckpt[\"model\"] if \"model\" in ckpt else ckpt\nmodel.load_state_dict(state, strict=True)\n    \n# Now, call the function to get the count\ntotal_params = count_parameters(model)\nprint(f\"Total Trainable Parameters: {total_params:}\")\n\nestimated_size = total_params * 4 / 1000 # FP32 precision\nprint(f\"Estimated Size: {estimated_size:,} KB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:02:05.144006Z","iopub.execute_input":"2025-09-04T10:02:05.144304Z","iopub.status.idle":"2025-09-04T10:02:05.188476Z","shell.execute_reply.started":"2025-09-04T10:02:05.144282Z","shell.execute_reply":"2025-09-04T10:02:05.187825Z"}},"outputs":[{"name":"stdout","text":"✅ Successfully loaded checkpoint from /kaggle/working/validation_runs/LR_0.0004_WD_0.0001_SCH_cosine_X1/best_model.pth\nTotal Trainable Parameters: 7019\nEstimated Size: 28.076 KB\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from torchinfo import summary\n\nckpt = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\n\nmodel = DepthwiseEarlyExitCNN1D(\n    if_train=False,\n    train_shape=ckpt.get(\"train_shape\", train_loader.dataset[0][0].shape),\n    n_io=len(ckpt.get(\"io_classes\", train_dataset.io_label_encoder.classes_)),\n    n_scene=len(ckpt.get(\"scene_classes\", train_dataset.scene_label_encoder.classes_))\n).to(device)\n\nstate = ckpt[\"model\"] if \"model\" in ckpt else ckpt\nmodel.load_state_dict(state, strict=True)\n\n# Print summary\nsummary(\n    model,\n    input_size=(1, 600, 11), \n    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"],\n    verbose=2,  # Detailed output\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-04T10:02:55.514463Z","iopub.execute_input":"2025-09-04T10:02:55.515257Z","iopub.status.idle":"2025-09-04T10:02:55.574739Z","shell.execute_reply.started":"2025-09-04T10:02:55.515227Z","shell.execute_reply":"2025-09-04T10:02:55.574092Z"}},"outputs":[{"name":"stdout","text":"=====================================================================================================================================================================\nLayer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n=====================================================================================================================================================================\nDepthwiseEarlyExitCNN1D                  [1, 600, 11]              [1, 2]                    6,278                     --                        --\n├─Sequential: 1-1                        [1, 11, 600]              [1, 16, 150]              --                        --                        --\n│    └─0.0.weight                                                                            ├─77                      [11, 1, 7]\n│    └─0.1.weight                                                                            ├─11                      [11]\n│    └─0.1.bias                                                                              ├─11                      [11]\n│    └─0.3.weight                                                                            ├─176                     [16, 11, 1]\n│    └─0.4.weight                                                                            ├─16                      [16]\n│    └─0.4.bias                                                                              ├─16                      [16]\n│    └─1.0.weight                                                                            ├─80                      [16, 1, 5]\n│    └─1.1.weight                                                                            ├─16                      [16]\n│    └─1.1.bias                                                                              ├─16                      [16]\n│    └─1.3.weight                                                                            ├─256                     [16, 16, 1]\n│    └─1.4.weight                                                                            ├─16                      [16]\n│    └─1.4.bias                                                                              └─16                      [16]\n│    └─Sequential: 2-1                   [1, 11, 600]              [1, 16, 300]              --                        --                        --\n│    │    └─0.weight                                                                         ├─77                      [11, 1, 7]\n│    │    └─1.weight                                                                         ├─11                      [11]\n│    │    └─1.bias                                                                           ├─11                      [11]\n│    │    └─3.weight                                                                         ├─176                     [16, 11, 1]\n│    │    └─4.weight                                                                         ├─16                      [16]\n│    │    └─4.bias                                                                           └─16                      [16]\n│    │    └─Conv1d: 3-1                  [1, 11, 600]              [1, 11, 300]              77                        [7]                       23,100\n│    │    │    └─weight                                                                      └─77                      [1, 11, 7]\n│    │    └─BatchNorm1d: 3-2             [1, 11, 300]              [1, 11, 300]              22                        --                        22\n│    │    │    └─weight                                                                      ├─11                      [11]\n│    │    │    └─bias                                                                        └─11                      [11]\n│    │    └─ReLU: 3-3                    [1, 11, 300]              [1, 11, 300]              --                        --                        --\n│    │    └─Conv1d: 3-4                  [1, 11, 300]              [1, 16, 300]              176                       [1]                       52,800\n│    │    │    └─weight                                                                      └─176                     [11, 16, 1]\n│    │    └─BatchNorm1d: 3-5             [1, 16, 300]              [1, 16, 300]              32                        --                        32\n│    │    │    └─weight                                                                      ├─16                      [16]\n│    │    │    └─bias                                                                        └─16                      [16]\n│    │    └─ReLU: 3-6                    [1, 16, 300]              [1, 16, 300]              --                        --                        --\n│    │    └─Dropout1d: 3-7               [1, 16, 300]              [1, 16, 300]              --                        --                        --\n│    └─Sequential: 2-2                   [1, 16, 300]              [1, 16, 150]              --                        --                        --\n│    │    └─0.weight                                                                         ├─80                      [16, 1, 5]\n│    │    └─1.weight                                                                         ├─16                      [16]\n│    │    └─1.bias                                                                           ├─16                      [16]\n│    │    └─3.weight                                                                         ├─256                     [16, 16, 1]\n│    │    └─4.weight                                                                         ├─16                      [16]\n│    │    └─4.bias                                                                           └─16                      [16]\n│    │    └─Conv1d: 3-8                  [1, 16, 300]              [1, 16, 150]              80                        [5]                       12,000\n│    │    │    └─weight                                                                      └─80                      [1, 16, 5]\n│    │    └─BatchNorm1d: 3-9             [1, 16, 150]              [1, 16, 150]              32                        --                        32\n│    │    │    └─weight                                                                      ├─16                      [16]\n│    │    │    └─bias                                                                        └─16                      [16]\n│    │    └─ReLU: 3-10                   [1, 16, 150]              [1, 16, 150]              --                        --                        --\n│    │    └─Conv1d: 3-11                 [1, 16, 150]              [1, 16, 150]              256                       [1]                       38,400\n│    │    │    └─weight                                                                      └─256                     [16, 16, 1]\n│    │    └─BatchNorm1d: 3-12            [1, 16, 150]              [1, 16, 150]              32                        --                        32\n│    │    │    └─weight                                                                      ├─16                      [16]\n│    │    │    └─bias                                                                        └─16                      [16]\n│    │    └─ReLU: 3-13                   [1, 16, 150]              [1, 16, 150]              --                        --                        --\n│    │    └─Dropout1d: 3-14              [1, 16, 150]              [1, 16, 150]              --                        --                        --\n├─Sequential: 1-2                        [1, 16, 150]              [1, 2]                    --                        --                        --\n│    └─2.weight                                                                              ├─32                      [2, 16]\n│    └─2.bias                                                                                └─2                       [2]\n│    └─AdaptiveAvgPool1d: 2-3            [1, 16, 150]              [1, 16, 1]                --                        --                        --\n│    └─Flatten: 2-4                      [1, 16, 1]                [1, 16]                   --                        --                        --\n│    └─Linear: 2-5                       [1, 16]                   [1, 2]                    34                        --                        34\n│    │    └─weight                                                                           ├─32                      [16, 2]\n│    │    └─bias                                                                             └─2                       [2]\n=====================================================================================================================================================================\nTotal params: 7,019\nTrainable params: 7,019\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.13\n=====================================================================================================================================================================\nInput size (MB): 0.03\nForward/backward pass size (MB): 0.21\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.24\n=====================================================================================================================================================================\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"=====================================================================================================================================================================\nLayer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n=====================================================================================================================================================================\nDepthwiseEarlyExitCNN1D                  [1, 600, 11]              [1, 2]                    6,278                     --                        --\n├─Sequential: 1-1                        [1, 11, 600]              [1, 16, 150]              --                        --                        --\n│    └─0.0.weight                                                                            ├─77                      [11, 1, 7]\n│    └─0.1.weight                                                                            ├─11                      [11]\n│    └─0.1.bias                                                                              ├─11                      [11]\n│    └─0.3.weight                                                                            ├─176                     [16, 11, 1]\n│    └─0.4.weight                                                                            ├─16                      [16]\n│    └─0.4.bias                                                                              ├─16                      [16]\n│    └─1.0.weight                                                                            ├─80                      [16, 1, 5]\n│    └─1.1.weight                                                                            ├─16                      [16]\n│    └─1.1.bias                                                                              ├─16                      [16]\n│    └─1.3.weight                                                                            ├─256                     [16, 16, 1]\n│    └─1.4.weight                                                                            ├─16                      [16]\n│    └─1.4.bias                                                                              └─16                      [16]\n│    └─Sequential: 2-1                   [1, 11, 600]              [1, 16, 300]              --                        --                        --\n│    │    └─0.weight                                                                         ├─77                      [11, 1, 7]\n│    │    └─1.weight                                                                         ├─11                      [11]\n│    │    └─1.bias                                                                           ├─11                      [11]\n│    │    └─3.weight                                                                         ├─176                     [16, 11, 1]\n│    │    └─4.weight                                                                         ├─16                      [16]\n│    │    └─4.bias                                                                           └─16                      [16]\n│    │    └─Conv1d: 3-1                  [1, 11, 600]              [1, 11, 300]              77                        [7]                       23,100\n│    │    │    └─weight                                                                      └─77                      [1, 11, 7]\n│    │    └─BatchNorm1d: 3-2             [1, 11, 300]              [1, 11, 300]              22                        --                        22\n│    │    │    └─weight                                                                      ├─11                      [11]\n│    │    │    └─bias                                                                        └─11                      [11]\n│    │    └─ReLU: 3-3                    [1, 11, 300]              [1, 11, 300]              --                        --                        --\n│    │    └─Conv1d: 3-4                  [1, 11, 300]              [1, 16, 300]              176                       [1]                       52,800\n│    │    │    └─weight                                                                      └─176                     [11, 16, 1]\n│    │    └─BatchNorm1d: 3-5             [1, 16, 300]              [1, 16, 300]              32                        --                        32\n│    │    │    └─weight                                                                      ├─16                      [16]\n│    │    │    └─bias                                                                        └─16                      [16]\n│    │    └─ReLU: 3-6                    [1, 16, 300]              [1, 16, 300]              --                        --                        --\n│    │    └─Dropout1d: 3-7               [1, 16, 300]              [1, 16, 300]              --                        --                        --\n│    └─Sequential: 2-2                   [1, 16, 300]              [1, 16, 150]              --                        --                        --\n│    │    └─0.weight                                                                         ├─80                      [16, 1, 5]\n│    │    └─1.weight                                                                         ├─16                      [16]\n│    │    └─1.bias                                                                           ├─16                      [16]\n│    │    └─3.weight                                                                         ├─256                     [16, 16, 1]\n│    │    └─4.weight                                                                         ├─16                      [16]\n│    │    └─4.bias                                                                           └─16                      [16]\n│    │    └─Conv1d: 3-8                  [1, 16, 300]              [1, 16, 150]              80                        [5]                       12,000\n│    │    │    └─weight                                                                      └─80                      [1, 16, 5]\n│    │    └─BatchNorm1d: 3-9             [1, 16, 150]              [1, 16, 150]              32                        --                        32\n│    │    │    └─weight                                                                      ├─16                      [16]\n│    │    │    └─bias                                                                        └─16                      [16]\n│    │    └─ReLU: 3-10                   [1, 16, 150]              [1, 16, 150]              --                        --                        --\n│    │    └─Conv1d: 3-11                 [1, 16, 150]              [1, 16, 150]              256                       [1]                       38,400\n│    │    │    └─weight                                                                      └─256                     [16, 16, 1]\n│    │    └─BatchNorm1d: 3-12            [1, 16, 150]              [1, 16, 150]              32                        --                        32\n│    │    │    └─weight                                                                      ├─16                      [16]\n│    │    │    └─bias                                                                        └─16                      [16]\n│    │    └─ReLU: 3-13                   [1, 16, 150]              [1, 16, 150]              --                        --                        --\n│    │    └─Dropout1d: 3-14              [1, 16, 150]              [1, 16, 150]              --                        --                        --\n├─Sequential: 1-2                        [1, 16, 150]              [1, 2]                    --                        --                        --\n│    └─2.weight                                                                              ├─32                      [2, 16]\n│    └─2.bias                                                                                └─2                       [2]\n│    └─AdaptiveAvgPool1d: 2-3            [1, 16, 150]              [1, 16, 1]                --                        --                        --\n│    └─Flatten: 2-4                      [1, 16, 1]                [1, 16]                   --                        --                        --\n│    └─Linear: 2-5                       [1, 16]                   [1, 2]                    34                        --                        34\n│    │    └─weight                                                                           ├─32                      [16, 2]\n│    │    └─bias                                                                             └─2                       [2]\n=====================================================================================================================================================================\nTotal params: 7,019\nTrainable params: 7,019\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.13\n=====================================================================================================================================================================\nInput size (MB): 0.03\nForward/backward pass size (MB): 0.21\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.24\n====================================================================================================================================================================="},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Sensor evals","metadata":{}},{"cell_type":"code","source":"def evaluate_sensor_subset(model, loader, battery_level, sensor_slices, active_sensors):\n    model.eval()\n    device = next(model.parameters()).device\n\n    # number of channels (last dim in [B, T, C])\n    C = loader.dataset[0][0].shape[1]\n\n    # Build mask: shape [1, 1, C]\n    mask = torch.zeros(1, 1, C, device=device)\n    for i in active_sensors:\n        c0, c1 = sensor_slices[i]\n        mask[..., c0:c1] = 1.0\n\n    real_forward = model.forward\n\n    def fwd_with_mask(x, battery_level=None, *args, **kwargs):\n        # x is [B, T, C]\n        x = x.to(device) * mask   # broadcasted over B and T\n        return real_forward(x, battery_level=battery_level, *args, **kwargs)\n\n    model.forward = fwd_with_mask\n    try:\n        results = evaluate_model_comprehensive(\n            model, loader, battery_level,\n            apply_posthoc_rule=True, verbose=False\n        )\n    finally:\n        model.forward = real_forward\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:13:25.516251Z","iopub.execute_input":"2025-08-29T15:13:25.516600Z","iopub.status.idle":"2025-08-29T15:13:25.523580Z","shell.execute_reply.started":"2025-08-29T15:13:25.516575Z","shell.execute_reply":"2025-08-29T15:13:25.522548Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def validate_and_report_slices(loader, sensor_slices, sensor_names):\n    # Get one batch to learn channel count C from [B, T, C]\n    xb, _, _ = next(iter(loader))\n    C = xb.shape[2]\n    print(f\"[check] batch shape: {tuple(xb.shape)}  -> C={C} channels\\n\")\n\n    # 0) Basic validations\n    ok = True\n    for i,(s,e) in enumerate(sensor_slices):\n        name = sensor_names[i] if i < len(sensor_names) else f\"sensor_{i}\"\n        if not isinstance(s,int) or not isinstance(e,int):\n            print(f\"❌ {name}: slice has non-integers ({s},{e})\")\n            ok = False\n        if s < 0 or e < 0:\n            print(f\"❌ {name}: negative indices ({s},{e}) not allowed\")\n            ok = False\n        if e <= s:\n            print(f\"❌ {name}: empty or reversed slice ({s},{e})\")\n            ok = False\n        if e > C:\n            print(f\"❌ {name}: out of bounds ({s},{e}) with C={C}\")\n            ok = False\n    if not ok:\n        print(\"\\n▲ Fix the issues above (slices must satisfy 0 ≤ s < e ≤ C).\")\n        return\n\n    # 1) Per-channel std over entire loader (quick estimate)\n    ch_sum = torch.zeros(C, dtype=torch.float64)\n    ch_sq  = torch.zeros(C, dtype=torch.float64)\n    n = 0\n    for x, _, _ in loader:          # x: [B, T, C]\n        x = x.double()\n        ch_sum += x.sum(dim=(0,1))\n        ch_sq  += (x*x).sum(dim=(0,1))\n        n += x.shape[0]*x.shape[1]\n    mean = ch_sum / n\n    var  = ch_sq/n - mean*mean\n    std  = torch.sqrt(torch.clamp(var, min=0))\n\n    print(\"[check] first 16 channel stds:\", [float(v) for v in std[:16]])\n    print()\n\n    # 2) Slice-level summary\n    for i,(s,e) in enumerate(sensor_slices):\n        name = sensor_names[i] if i < len(sensor_names) else f\"sensor_{i}\"\n        s_std = std[s:e]\n        print(f\"{name:>6} [{s}:{e}] | #ch={e-s:2d} | mean(std)={float(s_std.mean()):.6f} | \"\n              f\"min={float(s_std.min()):.6f} | max={float(s_std.max()):.6f}\")\n\n# Example call\nsensor_slices = [(0,3), (3,6), (6,9), (9,10), (10,11)]\nsensor_names  = [\"Acc\",\"Mag\",\"Gyro\",\"Press\",\"Temp\"]\nvalidate_and_report_slices(test_loader, sensor_slices, sensor_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T14:59:43.341654Z","iopub.execute_input":"2025-08-29T14:59:43.342359Z","iopub.status.idle":"2025-08-29T14:59:53.739612Z","shell.execute_reply.started":"2025-08-29T14:59:43.342338Z","shell.execute_reply":"2025-08-29T14:59:53.738581Z"}},"outputs":[{"name":"stdout","text":"[check] batch shape: (1, 600, 11)  -> C=11 channels\n\n[check] first 16 channel stds: [0.165741044079115, 0.24515662842706037, 0.1284300190097351, 0.24246848751325836, 0.32969938474918836, 0.26948395287855714, 32211.69874592251, 16719.12788016055, 16896.599518523115, 4.432100791958711, 6.279288347747939]\n\n   Acc [0:3] | #ch= 3 | mean(std)=0.179776 | min=0.128430 | max=0.245157\n   Mag [3:6] | #ch= 3 | mean(std)=0.280551 | min=0.242468 | max=0.329699\n  Gyro [6:9] | #ch= 3 | mean(std)=21942.475382 | min=16719.127880 | max=32211.698746\n Press [9:10] | #ch= 1 | mean(std)=4.432101 | min=4.432101 | max=4.432101\n  Temp [10:11] | #ch= 1 | mean(std)=6.279288 | min=6.279288 | max=6.279288\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Battery = 90%","metadata":{}},{"cell_type":"code","source":"import itertools\nimport json\nimport os\n\nckpt = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\n\nmodel = DepthwiseEarlyExitCNN1D(\n    if_train=False,\n    train_shape=ckpt.get(\"train_shape\", train_loader.dataset[0][0].shape),\n    n_io=len(ckpt.get(\"io_classes\", train_dataset.io_label_encoder.classes_)),\n    n_scene=len(ckpt.get(\"scene_classes\", train_dataset.scene_label_encoder.classes_))\n).to(device)\n\nstate = ckpt[\"model\"] if \"model\" in ckpt else ckpt\nmodel.load_state_dict(state, strict=True)\n\n# battery_levels = np.linspace(0, 1, 11)\nsensor_slices = [(0,3), (3,6), (6,9), (9,10), (10,11)]\nsensor_indices = [0, 1, 2, 3, 4]\nsensor_names = [\"Acc\", \"Mag\", \"Gyro\", \"Press\", \"Temp\"]\n\n# Generate all non-empty subsets (combinations) of sensor indices\nall_combinations = [\n    list(combo)\n    for r in range(1, len(sensor_indices) + 1)\n    for combo in itertools.combinations(sensor_indices, r)\n]\n\n# Evaluate each combination and collect results\nresults = []\nfor i, combo in enumerate(all_combinations, start=1):\n    print(f\"Iteration {i}/{len(all_combinations)} Evaluating combo: {combo}\")\n\n    # Mask inactive sensors and evaluate\n    res = evaluate_sensor_subset(\n        model=model,\n        loader=test_loader,\n        battery_level=0.9,                # or try a grid of values\n        sensor_slices=sensor_slices,\n        active_sensors=combo\n    )\n\n    # Map indices to names for readability\n    res[\"active_sensor_names\"] = [sensor_names[j] for j in combo]\n    results.append(res)\n\n    print(f\"\\n{'='*70}\\n\")\n\n# Define output filepath\noutput_path = \"/kaggle/working/90.json\"\nwith open(output_path, \"w\") as f:\n    json.dump(results, f, indent=2)\n\nprint(f\"Saved evaluation results for {len(results)} combinations\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T13:58:49.828142Z","iopub.execute_input":"2025-08-29T13:58:49.828425Z","iopub.status.idle":"2025-08-29T14:12:37.782010Z","shell.execute_reply.started":"2025-08-29T13:58:49.828401Z","shell.execute_reply":"2025-08-29T14:12:37.781190Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Iteration 1/31 Evaluating combo: [0]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 2/31 Evaluating combo: [1]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 3/31 Evaluating combo: [2]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 4/31 Evaluating combo: [3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 71.0% (3794 samples)\n  Exit 2 (Late):  29.0% (1548 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.772\n  I/O @ Exit 2:     0.625\n  Scene @ Exit 2:   0.169\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 1.000 (3809/3809)\n   Outdoor: 0.057 (  88/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 1.000 ( 257/ 257)\n   Hallway: 0.000 (   0/ 449)\n    Office: 0.000 (   0/ 262)\n    Street: 0.009 (   5/ 580)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.966, σ=0.064\n     Outdoor: μ=0.917, σ=0.127\n  By Exit:\n       exit1: μ=0.995, σ=0.005, n=3794\n       exit2: μ=0.845, σ=0.108, n=1548\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.631\n  I/O (Late final):      0.481\n  I/O (Late E0 baseline): 0.610\n  Scene (Raw):           0.054\n  Scene (Final):         0.054\n\n======================================================================\n\nIteration 5/31 Evaluating combo: [4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 6/31 Evaluating combo: [0, 1]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 7/31 Evaluating combo: [0, 2]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 8/31 Evaluating combo: [0, 3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 0.0% (1 samples)\n  Exit 2 (Late):  100.0% (5341 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     1.000\n  I/O @ Exit 2:     0.759\n  Scene @ Exit 2:   0.656\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.797 (3036/3809)\n   Outdoor: 0.665 (1019/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.216 ( 179/ 827)\n   Hallway: 0.793 ( 870/1097)\n    Office: 0.761 (1434/1884)\n    Street: 0.666 (1021/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.773, σ=0.123\n     Outdoor: μ=0.716, σ=0.120\n  By Exit:\n       exit1: μ=0.985, σ=0.000, n=1\n       exit2: μ=0.757, σ=0.124, n=5341\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.764\n  I/O (Late final):      0.764\n  I/O (Late E0 baseline): 0.813\n  Scene (Raw):           0.583\n  Scene (Final):         0.639\n\n======================================================================\n\nIteration 9/31 Evaluating combo: [0, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 10/31 Evaluating combo: [1, 2]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 11/31 Evaluating combo: [1, 3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 60.5% (3233 samples)\n  Exit 2 (Late):  39.5% (2109 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.720\n  I/O @ Exit 2:     0.672\n  Scene @ Exit 2:   0.177\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.966 (3680/3809)\n   Outdoor: 0.043 (  66/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.545 ( 104/ 191)\n   Hallway: 0.000 (   0/ 490)\n    Office: 0.000 (   0/ 737)\n    Street: 0.389 ( 269/ 691)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.924, σ=0.129\n     Outdoor: μ=0.928, σ=0.110\n  By Exit:\n       exit1: μ=0.994, σ=0.005, n=3233\n       exit2: μ=0.820, σ=0.142, n=2109\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.608\n  I/O (Late final):      0.541\n  I/O (Late E0 baseline): 0.676\n  Scene (Raw):           0.145\n  Scene (Final):         0.145\n\n======================================================================\n\nIteration 12/31 Evaluating combo: [1, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 13/31 Evaluating combo: [2, 3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 72.2% (3856 samples)\n  Exit 2 (Late):  27.8% (1486 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.775\n  I/O @ Exit 2:     0.592\n  Scene @ Exit 2:   0.450\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 1.000 (3809/3809)\n   Outdoor: 0.039 (  60/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.248 (  64/ 258)\n   Hallway: 0.062 (  23/ 368)\n    Office: 0.000 (   0/ 254)\n    Street: 0.959 ( 581/ 606)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.969, σ=0.070\n     Outdoor: μ=0.908, σ=0.140\n  By Exit:\n       exit1: μ=0.996, σ=0.005, n=3856\n       exit2: μ=0.838, σ=0.132, n=1486\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.619\n  I/O (Late final):      0.441\n  I/O (Late E0 baseline): 0.555\n  Scene (Raw):           0.333\n  Scene (Final):         0.333\n\n======================================================================\n\nIteration 14/31 Evaluating combo: [2, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 15/31 Evaluating combo: [3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 73.4% (3920 samples)\n  Exit 2 (Late):  26.6% (1422 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.779\n  I/O @ Exit 2:     0.589\n  Scene @ Exit 2:   0.257\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 1.000 (3809/3809)\n   Outdoor: 0.053 (  81/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.432 ( 111/ 257)\n   Hallway: 0.000 (   0/ 322)\n    Office: 0.984 ( 254/ 258)\n    Street: 0.002 (   1/ 585)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.969, σ=0.075\n     Outdoor: μ=0.928, σ=0.112\n  By Exit:\n       exit1: μ=0.997, σ=0.003, n=3920\n       exit2: μ=0.849, σ=0.118, n=1422\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.628\n  I/O (Late final):      0.436\n  I/O (Late E0 baseline): 0.569\n  Scene (Raw):           0.136\n  Scene (Final):         0.136\n\n======================================================================\n\nIteration 16/31 Evaluating combo: [0, 1, 2]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 17/31 Evaluating combo: [0, 1, 3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 3.5% (186 samples)\n  Exit 2 (Late):  96.5% (5156 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.849\n  I/O @ Exit 2:     0.807\n  Scene @ Exit 2:   0.669\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.808 (3077/3809)\n   Outdoor: 0.810 (1241/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.451 ( 372/ 824)\n   Hallway: 0.577 ( 617/1069)\n    Office: 0.728 (1368/1880)\n    Street: 0.791 (1094/1383)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.754, σ=0.127\n     Outdoor: μ=0.839, σ=0.135\n  By Exit:\n       exit1: μ=0.986, σ=0.006, n=186\n       exit2: μ=0.771, σ=0.131, n=5156\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.814\n  I/O (Late final):      0.814\n  I/O (Late E0 baseline): 0.833\n  Scene (Raw):           0.691\n  Scene (Final):         0.670\n\n======================================================================\n\nIteration 18/31 Evaluating combo: [0, 1, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 19/31 Evaluating combo: [0, 2, 3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 0.4% (20 samples)\n  Exit 2 (Late):  99.6% (5322 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.950\n  I/O @ Exit 2:     0.782\n  Scene @ Exit 2:   0.687\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.816 (3109/3809)\n   Outdoor: 0.699 (1072/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.164 ( 136/ 827)\n   Hallway: 0.798 ( 875/1096)\n    Office: 0.845 (1592/1884)\n    Street: 0.696 (1054/1515)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.779, σ=0.129\n     Outdoor: μ=0.730, σ=0.153\n  By Exit:\n       exit1: μ=0.984, σ=0.006, n=20\n       exit2: μ=0.764, σ=0.138, n=5322\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.787\n  I/O (Late final):      0.786\n  I/O (Late E0 baseline): 0.823\n  Scene (Raw):           0.661\n  Scene (Final):         0.660\n\n======================================================================\n\nIteration 20/31 Evaluating combo: [0, 2, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 99.9% (5339 samples)\n  Exit 2 (Late):  0.1% (3 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n📋 Per-Class Scene Accuracy:\n   Hallway: 0.000 (   0/   3)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.002\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.001, n=5339\n       exit2: μ=0.971, σ=0.007, n=3\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 21/31 Evaluating combo: [0, 3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 0.0% (1 samples)\n  Exit 2 (Late):  100.0% (5341 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     1.000\n  I/O @ Exit 2:     0.799\n  Scene @ Exit 2:   0.666\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.925 (3523/3809)\n   Outdoor: 0.485 ( 744/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.221 ( 183/ 827)\n   Hallway: 0.912 (1001/1097)\n    Office: 0.858 (1617/1884)\n    Street: 0.492 ( 754/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.806, σ=0.130\n     Outdoor: μ=0.680, σ=0.113\n  By Exit:\n       exit1: μ=0.990, σ=0.000, n=1\n       exit2: μ=0.769, σ=0.138, n=5341\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.785\n  I/O (Late final):      0.785\n  I/O (Late E0 baseline): 0.815\n  Scene (Raw):           0.578\n  Scene (Final):         0.640\n\n======================================================================\n\nIteration 22/31 Evaluating combo: [1, 2, 3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 62.2% (3322 samples)\n  Exit 2 (Late):  37.8% (2020 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.719\n  I/O @ Exit 2:     0.660\n  Scene @ Exit 2:   0.368\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.974 (3710/3809)\n   Outdoor: 0.008 (  13/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.200 (  41/ 205)\n   Hallway: 0.230 (  97/ 422)\n    Office: 0.000 (   0/ 706)\n    Street: 0.882 ( 606/ 687)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.930, σ=0.123\n     Outdoor: μ=0.910, σ=0.136\n  By Exit:\n       exit1: μ=0.994, σ=0.005, n=3322\n       exit2: μ=0.809, σ=0.146, n=2020\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.590\n  I/O (Late final):      0.525\n  I/O (Late E0 baseline): 0.715\n  Scene (Raw):           0.273\n  Scene (Final):         0.273\n\n======================================================================\n\nIteration 23/31 Evaluating combo: [1, 2, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 24/31 Evaluating combo: [1, 3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 67.1% (3584 samples)\n  Exit 2 (Late):  32.9% (1758 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.748\n  I/O @ Exit 2:     0.606\n  Scene @ Exit 2:   0.442\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.970 (3694/3809)\n   Outdoor: 0.035 (  53/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.204 (  38/ 186)\n   Hallway: 0.000 (   0/ 317)\n    Office: 0.690 ( 388/ 562)\n    Street: 0.506 ( 351/ 693)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.948, σ=0.107\n     Outdoor: μ=0.919, σ=0.122\n  By Exit:\n       exit1: μ=0.995, σ=0.005, n=3584\n       exit2: μ=0.828, σ=0.140, n=1758\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.604\n  I/O (Late final):      0.457\n  I/O (Late E0 baseline): 0.658\n  Scene (Raw):           0.411\n  Scene (Final):         0.411\n\n======================================================================\n\nIteration 25/31 Evaluating combo: [2, 3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 74.6% (3987 samples)\n  Exit 2 (Late):  25.4% (1355 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.781\n  I/O @ Exit 2:     0.554\n  Scene @ Exit 2:   0.520\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 1.000 (3809/3809)\n   Outdoor: 0.035 (  54/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.369 (  94/ 255)\n   Hallway: 0.047 (  12/ 257)\n    Office: 0.075 (  18/ 239)\n    Street: 0.960 ( 580/ 604)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.973, σ=0.077\n     Outdoor: μ=0.920, σ=0.129\n  By Exit:\n       exit1: μ=0.997, σ=0.004, n=3987\n       exit2: μ=0.841, σ=0.141, n=1355\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.617\n  I/O (Late final):      0.395\n  I/O (Late E0 baseline): 0.513\n  Scene (Raw):           0.423\n  Scene (Final):         0.423\n\n======================================================================\n\nIteration 26/31 Evaluating combo: [0, 1, 2, 3]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 4.0% (214 samples)\n  Exit 2 (Late):  96.0% (5128 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.953\n  I/O @ Exit 2:     0.863\n  Scene @ Exit 2:   0.777\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.866 (3299/3809)\n   Outdoor: 0.870 (1333/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.538 ( 442/ 822)\n   Hallway: 0.682 ( 739/1083)\n    Office: 0.878 (1652/1881)\n    Street: 0.860 (1154/1342)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.774, σ=0.122\n     Outdoor: μ=0.830, σ=0.143\n  By Exit:\n       exit1: μ=0.987, σ=0.006, n=214\n       exit2: μ=0.781, σ=0.127, n=5128\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.870\n  I/O (Late final):      0.868\n  I/O (Late E0 baseline): 0.861\n  Scene (Raw):           0.796\n  Scene (Final):         0.775\n\n======================================================================\n\nIteration 27/31 Evaluating combo: [0, 1, 2, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 100.0% (5342 samples)\n  Exit 2 (Late):  0.0% (0 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.287\n  I/O @ Exit 2:     0.000\n  Scene @ Exit 2:   0.000\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.000 (   0/3809)\n   Outdoor: 1.000 (1533/1533)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=1.000, σ=0.000\n     Outdoor: μ=1.000, σ=0.000\n  By Exit:\n       exit1: μ=1.000, σ=0.000, n=5342\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.128\n  I/O (Late final):      0.000\n  I/O (Late E0 baseline): 0.000\n  Scene (Raw):           0.000\n  Scene (Final):         0.000\n\n======================================================================\n\nIteration 28/31 Evaluating combo: [0, 1, 3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 2.1% (111 samples)\n  Exit 2 (Late):  97.9% (5231 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.928\n  I/O @ Exit 2:     0.858\n  Scene @ Exit 2:   0.713\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.894 (3406/3809)\n   Outdoor: 0.774 (1187/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.471 ( 386/ 819)\n   Hallway: 0.751 ( 815/1085)\n    Office: 0.757 (1423/1880)\n    Street: 0.764 (1106/1447)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.802, σ=0.125\n     Outdoor: μ=0.815, σ=0.127\n  By Exit:\n       exit1: μ=0.986, σ=0.006, n=111\n       exit2: μ=0.802, σ=0.124, n=5231\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.861\n  I/O (Late final):      0.859\n  I/O (Late E0 baseline): 0.868\n  Scene (Raw):           0.703\n  Scene (Final):         0.712\n\n======================================================================\n\nIteration 29/31 Evaluating combo: [0, 2, 3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 0.1% (6 samples)\n  Exit 2 (Late):  99.9% (5336 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     1.000\n  I/O @ Exit 2:     0.832\n  Scene @ Exit 2:   0.702\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.951 (3622/3809)\n   Outdoor: 0.537 ( 823/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.173 ( 143/ 827)\n   Hallway: 0.890 ( 976/1097)\n    Office: 0.947 (1785/1884)\n    Street: 0.552 ( 843/1528)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.829, σ=0.130\n     Outdoor: μ=0.710, σ=0.125\n  By Exit:\n       exit1: μ=0.984, σ=0.006, n=6\n       exit2: μ=0.794, σ=0.139, n=5336\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.820\n  I/O (Late final):      0.820\n  I/O (Late E0 baseline): 0.816\n  Scene (Raw):           0.654\n  Scene (Final):         0.669\n\n======================================================================\n\nIteration 30/31 Evaluating combo: [1, 2, 3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 69.3% (3704 samples)\n  Exit 2 (Late):  30.7% (1638 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.748\n  I/O @ Exit 2:     0.601\n  Scene @ Exit 2:   0.413\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.985 (3752/3809)\n   Outdoor: 0.003 (   4/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.100 (  21/ 209)\n   Hallway: 0.058 (  16/ 277)\n    Office: 0.002 (   1/ 499)\n    Street: 0.977 ( 638/ 653)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.953, σ=0.100\n     Outdoor: μ=0.901, σ=0.147\n  By Exit:\n       exit1: μ=0.995, σ=0.005, n=3704\n       exit2: μ=0.809, σ=0.146, n=1638\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.590\n  I/O (Late final):      0.452\n  I/O (Late E0 baseline): 0.657\n  Scene (Raw):           0.282\n  Scene (Final):         0.282\n\n======================================================================\n\nIteration 31/31 Evaluating combo: [0, 1, 2, 3, 4]\n\n======================================================================\nCOMPREHENSIVE EVALUATION @ Battery Level 0.90\n======================================================================\n\n📊 Exit Coverage:\n  Exit 1 (Early): 2.4% (126 samples)\n  Exit 2 (Late):  97.6% (5216 samples)\n\n🎯 Overall Accuracy:\n  I/O @ Exit 1:     0.976\n  I/O @ Exit 2:     0.904\n  Scene @ Exit 2:   0.812\n\n📋 Per-Class I/O Accuracy:\n    Indoor: 0.945 (3599/3809)\n   Outdoor: 0.809 (1240/1533)\n\n📋 Per-Class Scene Accuracy:\n       Bar: 0.599 ( 489/ 817)\n   Hallway: 0.805 ( 865/1074)\n    Office: 0.904 (1698/1878)\n    Street: 0.819 (1185/1447)\n\n🎲 Confidence Analysis (Threshold: 0.977):\n  By Class:\n      Indoor: μ=0.834, σ=0.111\n     Outdoor: μ=0.800, σ=0.136\n  By Exit:\n       exit1: μ=0.986, σ=0.006, n=126\n       exit2: μ=0.820, σ=0.118, n=5216\n\n🏆 Weighted F1 Scores:\n  I/O (All samples):     0.905\n  I/O (Late final):      0.903\n  I/O (Late E0 baseline): 0.885\n  Scene (Raw):           0.802\n  Scene (Final):         0.810\n\n======================================================================\n\nSaved evaluation results for 31 combinations\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import itertools\nimport json\nimport os\nimport math # Aggiunto per la radice quadrata\n\ndef overall_accuracy_geometric_mean(results):\n    \"\"\"\n    Calcola l'accuratezza complessiva usando la media geometrica.\n    Assumiamo che 'results' sia il dizionario restituito da evaluate_sensor_subset o comprehensive.\n    \"\"\"\n    # Adattiamo le chiavi a quelle della tua funzione `evaluate_sensor_subset`\n    acc_io_exit1 = results['accuracy'][\"io_exit1\"] # I/O è all'uscita 1\n    acc_io_exit2 = results['accuracy'][\"io_exit2_final\"] # I/O è all'uscita 2\n    acc_scene_exit2 = results['accuracy'][\"scene_exit2\"] # Scene è all'uscita 2\n    exit1_rate = results['coverage']['exit1_pct'] / 100.0\n    exit2_rate = results['coverage']['exit2_pct'] / 100.0\n    \n    # Task 1: Accuratezza I/O (eseguito solo in exit 1 in questa funzione)\n    acc_io_total = (acc_io_exit1 * exit1_rate) + (acc_io_exit2 * exit2_rate)\n    acc_scene_effective = acc_scene_exit2 * exit2_rate\n    \n    epsilon = 1e-9\n    return math.sqrt((acc_io_total+epsilon) * (acc_scene_effective+epsilon))\n    \nckpt = torch.load(BEST_MODEL_PATH, map_location=device, weights_only=False)\n\nmodel = DepthwiseEarlyExitCNN1D(\n    if_train=False,\n    train_shape=ckpt.get(\"train_shape\", train_loader.dataset[0][0].shape),\n    n_io=len(ckpt.get(\"io_classes\", train_dataset.io_label_encoder.classes_)),\n    n_scene=len(ckpt.get(\"scene_classes\", train_dataset.scene_label_encoder.classes_))\n).to(device)\n\nstate = ckpt[\"model\"] if \"model\" in ckpt else ckpt\nmodel.load_state_dict(state, strict=True)\nprint(\"✅ Modello caricato con successo.\")\n\n# --- SETUP DELLA VALUTAZIONE ---\nbattery_levels_to_test = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\nsensor_slices = [(0,3), (3,6), (6,9), (9,10), (10,11)] # Slice corrette\nsensor_indices = [0, 1, 2, 3, 4]\nsensor_names = [\"Acc\", \"Mag\", \"Gyro\", \"Press\", \"Temp\"]\n\nall_combinations = [\n    list(combo)\n    for r in range(1, len(sensor_indices) + 1)\n    for combo in itertools.combinations(sensor_indices, r)\n]\n\n# --- LOOP PRINCIPALE SU OGNI LIVELLO DI BATTERIA ---\nfor battery_level in battery_levels_to_test:\n    print(f\"\\n{'='*80}\")\n    print(f\"INIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: {battery_level:.2f}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Lista per raccogliere i risultati di questo specifico livello di batteria\n    results_for_this_battery_level = []\n    \n    for i, combo in enumerate(all_combinations, start=1):\n        print(f\"--- Batteria {battery_level:.2f} | Iterazione {i}/{len(all_combinations)} | Combo: {combo} ---\")\n\n        # Esegui la valutazione per il sottoinsieme di sensori\n        # NOTA: Assicurati che la tua funzione `evaluate_sensor_subset` sia definita\n        # e funzioni correttamente con l'approccio di mascheramento o di subsetting.\n        res = evaluate_sensor_subset(\n            model=model,\n            loader=test_loader,\n            battery_level=battery_level,\n            sensor_slices=sensor_slices,\n            active_sensors=combo\n        )\n\n        # Mappa gli indici ai nomi per leggibilità\n        res[\"active_sensor_names\"] = [sensor_names[j] for j in combo]\n        \n        # Calcola e aggiungi la metrica di accuratezza complessiva\n        res[\"overall_accuracy_geometric\"] = overall_accuracy_geometric_mean(res)\n        \n        results_for_this_battery_level.append(res)\n\n    # --- SALVATAGGIO DEL FILE JSON PER QUESTO LIVELLO DI BATTERIA ---\n    # Crea un nome di file dinamico\n    battery_level_str = str(int(battery_level * 100)) # Converte 0.7 in \"70\"\n    output_path = f\"/kaggle/working/b{battery_level_str}.json\"\n    \n    # Salva i risultati in un file JSON\n    with open(output_path, \"w\") as f:\n        json.dump(results_for_this_battery_level, f, indent=2)\n\n    print(f\"\\n✅ Risultati di valutazione per Batteria = {battery_level:.2f} salvati in: {output_path}\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"TUTTE LE VALUTAZIONI SONO STATE COMPLETATE.\")\nprint(f\"{'='*80}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:14:03.706016Z","iopub.execute_input":"2025-08-29T15:14:03.706318Z","iopub.status.idle":"2025-08-29T18:20:58.692861Z","shell.execute_reply.started":"2025-08-29T15:14:03.706294Z","shell.execute_reply":"2025-08-29T18:20:58.691817Z"}},"outputs":[{"name":"stdout","text":"✅ Modello caricato con successo.\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.10\n================================================================================\n\n--- Batteria 0.10 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.10 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.10 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.10 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.10 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.10 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.10 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.10 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.10 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.10 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.10 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.10 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.10 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.10 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.10 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.10 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.10 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.10 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.10 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.10 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.10 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.10 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.10 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.10 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.10 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.10 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.10 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.10 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.10 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.10 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.10 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.10 salvati in: /kaggle/working/b10.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.20\n================================================================================\n\n--- Batteria 0.20 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.20 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.20 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.20 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.20 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.20 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.20 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.20 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.20 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.20 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.20 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.20 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.20 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.20 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.20 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.20 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.20 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.20 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.20 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.20 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.20 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.20 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.20 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.20 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.20 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.20 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.20 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.20 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.20 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.20 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.20 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.20 salvati in: /kaggle/working/b20.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.30\n================================================================================\n\n--- Batteria 0.30 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.30 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.30 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.30 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.30 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.30 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.30 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.30 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.30 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.30 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.30 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.30 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.30 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.30 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.30 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.30 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.30 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.30 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.30 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.30 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.30 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.30 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.30 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.30 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.30 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.30 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.30 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.30 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.30 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.30 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.30 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.30 salvati in: /kaggle/working/b30.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.40\n================================================================================\n\n--- Batteria 0.40 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.40 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.40 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.40 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.40 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.40 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.40 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.40 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.40 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.40 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.40 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.40 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.40 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.40 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.40 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.40 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.40 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.40 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.40 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.40 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.40 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.40 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.40 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.40 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.40 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.40 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.40 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.40 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.40 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.40 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.40 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.40 salvati in: /kaggle/working/b40.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.50\n================================================================================\n\n--- Batteria 0.50 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.50 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.50 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.50 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.50 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.50 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.50 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.50 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.50 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.50 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.50 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.50 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.50 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.50 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.50 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.50 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.50 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.50 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.50 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.50 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.50 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.50 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.50 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.50 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.50 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.50 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.50 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.50 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.50 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.50 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.50 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.50 salvati in: /kaggle/working/b50.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.60\n================================================================================\n\n--- Batteria 0.60 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.60 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.60 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.60 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.60 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.60 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.60 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.60 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.60 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.60 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.60 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.60 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.60 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.60 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.60 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.60 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.60 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.60 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.60 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.60 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.60 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.60 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.60 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.60 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.60 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.60 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.60 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.60 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.60 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.60 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.60 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.60 salvati in: /kaggle/working/b60.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.70\n================================================================================\n\n--- Batteria 0.70 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.70 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.70 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.70 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.70 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.70 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.70 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.70 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.70 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.70 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.70 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.70 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.70 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.70 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.70 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.70 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.70 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.70 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.70 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.70 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.70 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.70 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.70 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.70 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.70 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.70 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.70 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.70 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.70 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.70 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.70 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.70 salvati in: /kaggle/working/b70.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.80\n================================================================================\n\n--- Batteria 0.80 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.80 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.80 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.80 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.80 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.80 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.80 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.80 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.80 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.80 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.80 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.80 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.80 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.80 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.80 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.80 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.80 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.80 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.80 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.80 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.80 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.80 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.80 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.80 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.80 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.80 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.80 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.80 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.80 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.80 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.80 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.80 salvati in: /kaggle/working/b80.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 0.90\n================================================================================\n\n--- Batteria 0.90 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 0.90 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 0.90 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 0.90 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 0.90 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 0.90 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 0.90 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 0.90 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 0.90 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 0.90 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 0.90 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 0.90 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 0.90 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 0.90 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 0.90 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 0.90 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 0.90 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 0.90 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 0.90 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 0.90 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 0.90 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 0.90 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 0.90 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 0.90 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 0.90 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 0.90 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 0.90 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 0.90 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 0.90 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 0.90 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 0.90 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 0.90 salvati in: /kaggle/working/b90.json\n\n================================================================================\nINIZIO VALUTAZIONE PER IL LIVELLO DI BATTERIA: 1.00\n================================================================================\n\n--- Batteria 1.00 | Iterazione 1/31 | Combo: [0] ---\n--- Batteria 1.00 | Iterazione 2/31 | Combo: [1] ---\n--- Batteria 1.00 | Iterazione 3/31 | Combo: [2] ---\n--- Batteria 1.00 | Iterazione 4/31 | Combo: [3] ---\n--- Batteria 1.00 | Iterazione 5/31 | Combo: [4] ---\n--- Batteria 1.00 | Iterazione 6/31 | Combo: [0, 1] ---\n--- Batteria 1.00 | Iterazione 7/31 | Combo: [0, 2] ---\n--- Batteria 1.00 | Iterazione 8/31 | Combo: [0, 3] ---\n--- Batteria 1.00 | Iterazione 9/31 | Combo: [0, 4] ---\n--- Batteria 1.00 | Iterazione 10/31 | Combo: [1, 2] ---\n--- Batteria 1.00 | Iterazione 11/31 | Combo: [1, 3] ---\n--- Batteria 1.00 | Iterazione 12/31 | Combo: [1, 4] ---\n--- Batteria 1.00 | Iterazione 13/31 | Combo: [2, 3] ---\n--- Batteria 1.00 | Iterazione 14/31 | Combo: [2, 4] ---\n--- Batteria 1.00 | Iterazione 15/31 | Combo: [3, 4] ---\n--- Batteria 1.00 | Iterazione 16/31 | Combo: [0, 1, 2] ---\n--- Batteria 1.00 | Iterazione 17/31 | Combo: [0, 1, 3] ---\n--- Batteria 1.00 | Iterazione 18/31 | Combo: [0, 1, 4] ---\n--- Batteria 1.00 | Iterazione 19/31 | Combo: [0, 2, 3] ---\n--- Batteria 1.00 | Iterazione 20/31 | Combo: [0, 2, 4] ---\n--- Batteria 1.00 | Iterazione 21/31 | Combo: [0, 3, 4] ---\n--- Batteria 1.00 | Iterazione 22/31 | Combo: [1, 2, 3] ---\n--- Batteria 1.00 | Iterazione 23/31 | Combo: [1, 2, 4] ---\n--- Batteria 1.00 | Iterazione 24/31 | Combo: [1, 3, 4] ---\n--- Batteria 1.00 | Iterazione 25/31 | Combo: [2, 3, 4] ---\n--- Batteria 1.00 | Iterazione 26/31 | Combo: [0, 1, 2, 3] ---\n--- Batteria 1.00 | Iterazione 27/31 | Combo: [0, 1, 2, 4] ---\n--- Batteria 1.00 | Iterazione 28/31 | Combo: [0, 1, 3, 4] ---\n--- Batteria 1.00 | Iterazione 29/31 | Combo: [0, 2, 3, 4] ---\n--- Batteria 1.00 | Iterazione 30/31 | Combo: [1, 2, 3, 4] ---\n--- Batteria 1.00 | Iterazione 31/31 | Combo: [0, 1, 2, 3, 4] ---\n\n✅ Risultati di valutazione per Batteria = 1.00 salvati in: /kaggle/working/b100.json\n\n================================================================================\nTUTTE LE VALUTAZIONI SONO STATE COMPLETATE.\n================================================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# TO DELETE THE /kaggle/working/ FILES","metadata":{}},{"cell_type":"code","source":"import shutil\nimport os\n\ndirectory_path = \"/kaggle/working/validation_runs/\"\n\nif os.path.exists(directory_path):\n    shutil.rmtree(directory_path)\n    print(f\"Deleted directory {directory_path}\")\nelse:\n    print(f\"Directory {directory_path} not found\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T08:44:43.018133Z","iopub.execute_input":"2025-08-29T08:44:43.018663Z","iopub.status.idle":"2025-08-29T08:44:43.026733Z","shell.execute_reply.started":"2025-08-29T08:44:43.018635Z","shell.execute_reply":"2025-08-29T08:44:43.026080Z"}},"outputs":[{"name":"stdout","text":"Deleted directory /kaggle/working/validation_runs/\n","output_type":"stream"}],"execution_count":9}]}